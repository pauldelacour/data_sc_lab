{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pldelacour/Documents/PL_Ecole/data_sc_lab/data_sc_lab/task_01/pipelines\n"
     ]
    }
   ],
   "source": [
    "cd ../task_01/pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipynb.fs.full.tool_functions import *\n",
    "from yellowbrick.regressor import AlphaSelection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (66,68,80,81,82,83,84,95,96,97,98,99,110,111,112,113,114,125,126,127,128,129,140,141,142,144,155,156,157,159,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1384,1385,1387,1390,1391,1393,1396,1397,1399,1402,1403,1405,1408,1409,1411,1414,1415,1417,1420,1421,1423,1426,1427,1429,1432,1433,1435,1438,1439,1441,1444,1445,1447,1450,1451,1453,1456,1457,1459,1462,1463,1465,1468,1469,1471,1474,1475,1477,1480,1481,1483,1486,1487,1489,1492,1493,1495,1498,1499,1501,1504,1505,1507,1510,1511,1513,1516,1517,1519,1522,1523,1525,1528,1529,1531,1534,1535,1537,1540,1541,1543,1546,1547,1549,1552,1553,1555,1558,1559,1561,1564,1565,1567,1570,1571,1573,1576,1577,1579,1582,1583,1585,1588,1589,1591,1594,1595,1597,1600,1601,1603,1606,1607,1609,1612,1613,1615,1618,1619,1621,1624,1625,1627,1630,1631,1633,1636,1637,1639,1642,1643,1645,1648,1649,1651,1654,1655,1657,1660,1661,1663,1666,1667,1669,1672,1673,1675,1678,1679,1681,1684,1685,1687,1690,1691,1693,1696,1697,1699,1702,1703,1705,1708,1709,1711,1714,1715,1717,1720,1721,1723,1726,1727,1729,1732,1733,1735,1738,1739,1741,1744,1745,1747,1750,1751,1753,1756,1757,1759,1762,1763,1765,1768,1769,1771,1774,1775,1777,1780,1781,1783,1786,1787,1789,1792,1793,1795,1798,1799,1801,1804,1805,1807,1810,1811,1813,1816,1817,1819,1822,1823,1825,1828,1829,1831,1834,1835,1837,1840,1841,1843,1846,1847,1849,1852,1853,1855,1858,1859,1861,1882,1883,1884,1917,1918,1919,1952,1953,1954,1955,1987,1988,1989,1990,2022,2023,2024,2025,2026,2057,2058,2059,2060,2061,2092,2093,2094,2095,2096,2097,2127,2128,2129,2130,2131,2132,2162,2163,2164,2165,2166,2167,2168,2197,2198,2199,2200,2201,2202,2203,2232,2233,2234,2235,2236,2237,2238,2239,2267,2268,2269,2270,2271,2272,2273,2274,2302,2303,2304,2305,2306,2307,2308,2309,2337,2338,2339,2340,2341,2342,2343,2344,2477,2478,2479,2512,2513,2514,2547,2548,2549,2550,2582,2583,2584,2585,2617,2618,2619,2620,2621,2652,2653,2654,2655,2656,2687,2688,2689,2690,2691,2692,2722,2723,2724,2725,2726,2727,2757,2758,2759,2760,2761,2762,2763,2792,2793,2794,2795,2796,2797,2798,2827,2828,2829,2830,2831,2832,2833,2834,2862,2863,2864,2865,2866,2867,2868,2869,2897,2898,2899,2900,2901,2902,2903,2904,2932,2933,2934,2935,2936,2937,2938,2939,3819,3826,3866,3933,4037,4055,4059,4063,4067,4071,4075,4079,4084,4085,4086,4087,4088,4091,4092,4094,4095,4096,4608,4616,4648,4649,4664,4665,4667,4683,4690,4691,4692,4693,4739,4800,5002,5010,5018,5026,5042,5240,5282,5386,5433,5443,5463,5466,5467,5468,5470,5478,5479,5481,5482,5483,5484,5485,5486,5487,5488,5489,5490,5491,5492,5495,5499,5503,5507,5511,5515,5517,5518,5519,5520,5521,5522,5523,5524,5532,5535,5536,5537,5539,5540,5548,5549,5551,5552,5553,5554,5555,5556,5557,5558,5559,5560,5561,5562,5565,5569,5573,5577,5581,5586,5587,5588,5589,5590,5591,5592,5593,5594,5601,5604,5605,5606,5608,5616,5617,5619,5620,5621,5622,5623,5624,5625,5626,5627,5628,5629,5630,5633,5636,5637,5638,5640,5648,5649,5651,5652,5653,5654,5655,5656,5657,5658,5659,5660,5661,5662,5665,5668,5669,5670,5672,5680,5681,5683,5684,5685,5686,5687,5688,5689,5690,5691,5692,5693,5694,5697,5700,5701,5702,5704,5712,5713,5715,5716,5717,5718,5719,5720,5721,5722,5723,5724,5725,5726,5729,5732,5733,5734,5736,5744,5745,5747,5748,5749,5750,5751,5752,5753,5754,5755,5756,5757,5758,5759,5760,5761,5762,5763,5764,5768,5772,5776,5780,5784,5788,5792,5796,5800,5804,5808,5812,5816,5820,5869,5877,5881,5885,5889,5893,5897,6538,6539,6540,6541,6542,6555,6556,6557,6558,6559,6572,6573,6574,6575,6576,6589,6590,6591,6592,6593,6606,6607,6608,6609,6610,6623,6624,6625,6626,6627,6636,6644,6650,6653,6682,6701,6738,6768) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_beha = pd.read_csv('../../../data/Behavioral/AllData.csv')#, nrows=1000)\n",
    "\n",
    "df_spectro_cluster = pd.read_csv(\"../../../data/EEG/RestingEEG_Spectro_Cluster.csv\") #, nrows=1000)\n",
    "\n",
    "srs = pd.read_csv('../../../data/HBN_srs.csv', delimiter=';')\n",
    "outliers = pd.read_csv('../../../data/outliers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "swan = df_beha[['SWAN_IN_Avg' , 'SWAN_HY_Avg', 'Patient_ID']]\n",
    "in_null = swan['SWAN_IN_Avg'].isnull().sum()\n",
    "hy_null = swan['SWAN_HY_Avg'].isnull().sum()\n",
    "#print(in_null)\n",
    "#print(hy_null)\n",
    "swan = swan[~ (swan['SWAN_IN_Avg'].isnull() | swan['SWAN_HY_Avg'].isnull()) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs = srs[~srs['SRS_RRB'].isnull()]\n",
    "srs.rename(columns={'IDs': 'Patient_ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SWAN_IN_Avg</th>\n",
       "      <th>SWAN_HY_Avg</th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SRS_RRB</th>\n",
       "      <th>SRS_SCI</th>\n",
       "      <th>SRS_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>NDARYM832PX3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.048254</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.555555</td>\n",
       "      <td>NDARNJ687DMC</td>\n",
       "      <td>1</td>\n",
       "      <td>6.348163</td>\n",
       "      <td>19.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.111111</td>\n",
       "      <td>1.888888</td>\n",
       "      <td>NDARED632KNG</td>\n",
       "      <td>1</td>\n",
       "      <td>17.203855</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.111111</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>NDARFM080VAF</td>\n",
       "      <td>1</td>\n",
       "      <td>7.623203</td>\n",
       "      <td>14.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.777777</td>\n",
       "      <td>NDARFW130NGG</td>\n",
       "      <td>1</td>\n",
       "      <td>8.316107</td>\n",
       "      <td>25.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>-1.444444</td>\n",
       "      <td>-2.333333</td>\n",
       "      <td>NDARND697FLK</td>\n",
       "      <td>1</td>\n",
       "      <td>6.517796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NDARCL008HLA</td>\n",
       "      <td>0</td>\n",
       "      <td>16.456194</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>-1.888888</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>NDARYM334BZ5</td>\n",
       "      <td>0</td>\n",
       "      <td>16.119438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>-0.666666</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>NDARYZ986HEW</td>\n",
       "      <td>1</td>\n",
       "      <td>7.563084</td>\n",
       "      <td>9.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NDARYA955CY1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.357859</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1239 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SWAN_IN_Avg  SWAN_HY_Avg    Patient_ID  Sex        Age  SRS_RRB  \\\n",
       "0        0.000000     1.222222  NDARYM832PX3    1   7.048254     10.0   \n",
       "1        1.222222     0.555555  NDARNJ687DMC    1   6.348163     19.0   \n",
       "2        1.111111     1.888888  NDARED632KNG    1  17.203855      2.0   \n",
       "3       -0.111111     2.222222  NDARFM080VAF    1   7.623203     14.0   \n",
       "4       -0.111111     0.777777  NDARFW130NGG    1   8.316107     25.0   \n",
       "...           ...          ...           ...  ...        ...      ...   \n",
       "1234    -1.444444    -2.333333  NDARND697FLK    1   6.517796      1.0   \n",
       "1235     1.222222     0.444444  NDARCL008HLA    0  16.456194     21.0   \n",
       "1236    -1.888888    -3.000000  NDARYM334BZ5    0  16.119438      0.0   \n",
       "1237    -0.666666     1.333333  NDARYZ986HEW    1   7.563084      9.0   \n",
       "1238     0.333333     0.000000  NDARYA955CY1    0  15.357859      4.0   \n",
       "\n",
       "      SRS_SCI  SRS_Total  \n",
       "0        45.0       55.0  \n",
       "1        73.0       92.0  \n",
       "2        28.0       30.0  \n",
       "3        72.0       86.0  \n",
       "4        85.0      110.0  \n",
       "...       ...        ...  \n",
       "1234     17.0       18.0  \n",
       "1235     82.0      103.0  \n",
       "1236      6.0        6.0  \n",
       "1237     49.0       58.0  \n",
       "1238     39.0       43.0  \n",
       "\n",
       "[1239 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.merge(swan , srs , on = 'Patient_ID')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine With spectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spectro_cluster.rename(columns={'id': 'Patient_ID'}, inplace=True)\n",
    "df_label_spectro_cluster = pd.merge(scores,  df_spectro_cluster, on='Patient_ID')\n",
    "\n",
    "df_label_spectro_cluster = fill_with_median(df_label_spectro_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_18 = df_label_spectro_cluster['Age'] <= 18.0\n",
    "df_label_spectro_cluster = df_label_spectro_cluster[less_18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove preidentified outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = pd.read_csv('../../../data/outliers.csv')\n",
    "df_label_spectro_cluster = df_label_spectro_cluster[~df_label_spectro_cluster.Patient_ID.isin(outliers.Patient_ID)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_label_spectro_cluster.drop([ 'SWAN_IN_Avg' , 'SWAN_HY_Avg', 'SRS_Total' , 'SRS_RRB' , 'SRS_SCI', 'Patient_ID'], axis=1)\n",
    "Y = df_label_spectro_cluster[[ 'SWAN_IN_Avg' , 'SWAN_HY_Avg', 'SRS_Total' , 'SRS_RRB' , 'SRS_SCI']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>eyesclosed_fband_delta_absmean_lfront</th>\n",
       "      <th>eyesclosed_fband_delta_absmean_mfront</th>\n",
       "      <th>eyesclosed_fband_delta_absmean_rfront</th>\n",
       "      <th>eyesclosed_fband_delta_absmean_lpari</th>\n",
       "      <th>eyesclosed_fband_delta_absmean_mpari</th>\n",
       "      <th>eyesclosed_fband_delta_absmean_rpari</th>\n",
       "      <th>eyesclosed_fband_delta_relmean_lfront</th>\n",
       "      <th>eyesclosed_fband_delta_relmean_mfront</th>\n",
       "      <th>...</th>\n",
       "      <th>eyesopen_fooof_peak_freq_rfront</th>\n",
       "      <th>eyesopen_fooof_peak_freq_lpari</th>\n",
       "      <th>eyesopen_fooof_peak_freq_mpari</th>\n",
       "      <th>eyesopen_fooof_peak_freq_rpari</th>\n",
       "      <th>eyesopen_fooof_peak_amplitude_lfront</th>\n",
       "      <th>eyesopen_fooof_peak_amplitude_mfront</th>\n",
       "      <th>eyesopen_fooof_peak_amplitude_rfront</th>\n",
       "      <th>eyesopen_fooof_peak_amplitude_lpari</th>\n",
       "      <th>eyesopen_fooof_peak_amplitude_mpari</th>\n",
       "      <th>eyesopen_fooof_peak_amplitude_rpari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.623203</td>\n",
       "      <td>7.519803</td>\n",
       "      <td>7.043891</td>\n",
       "      <td>6.528158</td>\n",
       "      <td>9.633529</td>\n",
       "      <td>9.989483</td>\n",
       "      <td>9.305804</td>\n",
       "      <td>9.598653</td>\n",
       "      <td>10.164125</td>\n",
       "      <td>...</td>\n",
       "      <td>9.485781</td>\n",
       "      <td>9.441022</td>\n",
       "      <td>9.384172</td>\n",
       "      <td>9.425798</td>\n",
       "      <td>0.795549</td>\n",
       "      <td>0.876262</td>\n",
       "      <td>0.872379</td>\n",
       "      <td>0.989101</td>\n",
       "      <td>1.099981</td>\n",
       "      <td>0.915441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10.835158</td>\n",
       "      <td>2.346685</td>\n",
       "      <td>3.945786</td>\n",
       "      <td>2.962716</td>\n",
       "      <td>3.440606</td>\n",
       "      <td>3.565384</td>\n",
       "      <td>3.023286</td>\n",
       "      <td>10.968235</td>\n",
       "      <td>12.461058</td>\n",
       "      <td>...</td>\n",
       "      <td>8.800915</td>\n",
       "      <td>8.510134</td>\n",
       "      <td>9.078390</td>\n",
       "      <td>14.741810</td>\n",
       "      <td>0.254701</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.303875</td>\n",
       "      <td>0.234960</td>\n",
       "      <td>0.232564</td>\n",
       "      <td>0.344537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7.987451</td>\n",
       "      <td>1.281869</td>\n",
       "      <td>1.229748</td>\n",
       "      <td>1.905450</td>\n",
       "      <td>1.768091</td>\n",
       "      <td>1.484286</td>\n",
       "      <td>0.756394</td>\n",
       "      <td>13.132905</td>\n",
       "      <td>11.998897</td>\n",
       "      <td>...</td>\n",
       "      <td>5.604535</td>\n",
       "      <td>5.602136</td>\n",
       "      <td>4.096616</td>\n",
       "      <td>5.084040</td>\n",
       "      <td>0.048655</td>\n",
       "      <td>0.233294</td>\n",
       "      <td>0.282735</td>\n",
       "      <td>0.256238</td>\n",
       "      <td>0.175123</td>\n",
       "      <td>0.304286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8.096851</td>\n",
       "      <td>3.109075</td>\n",
       "      <td>4.803264</td>\n",
       "      <td>2.873502</td>\n",
       "      <td>2.644382</td>\n",
       "      <td>3.884837</td>\n",
       "      <td>2.391569</td>\n",
       "      <td>9.931212</td>\n",
       "      <td>10.869944</td>\n",
       "      <td>...</td>\n",
       "      <td>9.288451</td>\n",
       "      <td>6.651558</td>\n",
       "      <td>6.396867</td>\n",
       "      <td>10.291086</td>\n",
       "      <td>0.218827</td>\n",
       "      <td>0.313734</td>\n",
       "      <td>0.298905</td>\n",
       "      <td>0.178899</td>\n",
       "      <td>0.108880</td>\n",
       "      <td>0.449437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.357061</td>\n",
       "      <td>5.786769</td>\n",
       "      <td>6.818487</td>\n",
       "      <td>6.296279</td>\n",
       "      <td>8.043145</td>\n",
       "      <td>9.413683</td>\n",
       "      <td>6.839451</td>\n",
       "      <td>10.495082</td>\n",
       "      <td>11.095547</td>\n",
       "      <td>...</td>\n",
       "      <td>6.952035</td>\n",
       "      <td>5.065536</td>\n",
       "      <td>4.679294</td>\n",
       "      <td>4.924409</td>\n",
       "      <td>0.150518</td>\n",
       "      <td>0.169058</td>\n",
       "      <td>0.154417</td>\n",
       "      <td>0.104574</td>\n",
       "      <td>0.102992</td>\n",
       "      <td>0.094126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>1</td>\n",
       "      <td>6.517796</td>\n",
       "      <td>8.594610</td>\n",
       "      <td>13.258798</td>\n",
       "      <td>7.158682</td>\n",
       "      <td>12.743212</td>\n",
       "      <td>8.698643</td>\n",
       "      <td>4.855232</td>\n",
       "      <td>15.315470</td>\n",
       "      <td>14.779320</td>\n",
       "      <td>...</td>\n",
       "      <td>5.868008</td>\n",
       "      <td>22.846455</td>\n",
       "      <td>7.050818</td>\n",
       "      <td>4.622321</td>\n",
       "      <td>0.416442</td>\n",
       "      <td>0.358625</td>\n",
       "      <td>0.380528</td>\n",
       "      <td>0.169463</td>\n",
       "      <td>0.325197</td>\n",
       "      <td>0.199935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>0</td>\n",
       "      <td>16.456194</td>\n",
       "      <td>7.487871</td>\n",
       "      <td>9.809903</td>\n",
       "      <td>7.255467</td>\n",
       "      <td>8.731814</td>\n",
       "      <td>9.629680</td>\n",
       "      <td>11.326718</td>\n",
       "      <td>7.404931</td>\n",
       "      <td>7.060421</td>\n",
       "      <td>...</td>\n",
       "      <td>9.389994</td>\n",
       "      <td>9.540163</td>\n",
       "      <td>9.482167</td>\n",
       "      <td>9.545163</td>\n",
       "      <td>1.326583</td>\n",
       "      <td>1.288238</td>\n",
       "      <td>1.407225</td>\n",
       "      <td>1.561878</td>\n",
       "      <td>1.636154</td>\n",
       "      <td>1.412149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>0</td>\n",
       "      <td>16.119438</td>\n",
       "      <td>3.743134</td>\n",
       "      <td>3.795633</td>\n",
       "      <td>3.286381</td>\n",
       "      <td>2.779438</td>\n",
       "      <td>3.539956</td>\n",
       "      <td>3.800533</td>\n",
       "      <td>8.565498</td>\n",
       "      <td>8.383859</td>\n",
       "      <td>...</td>\n",
       "      <td>10.376962</td>\n",
       "      <td>10.707490</td>\n",
       "      <td>10.383040</td>\n",
       "      <td>10.343315</td>\n",
       "      <td>0.623514</td>\n",
       "      <td>0.582917</td>\n",
       "      <td>0.422394</td>\n",
       "      <td>0.615360</td>\n",
       "      <td>0.860283</td>\n",
       "      <td>0.945789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>1</td>\n",
       "      <td>7.563084</td>\n",
       "      <td>2.830657</td>\n",
       "      <td>5.259391</td>\n",
       "      <td>6.724664</td>\n",
       "      <td>4.745513</td>\n",
       "      <td>5.885628</td>\n",
       "      <td>3.160138</td>\n",
       "      <td>13.388712</td>\n",
       "      <td>13.121943</td>\n",
       "      <td>...</td>\n",
       "      <td>9.482208</td>\n",
       "      <td>7.101976</td>\n",
       "      <td>9.409898</td>\n",
       "      <td>9.301044</td>\n",
       "      <td>0.185029</td>\n",
       "      <td>0.165101</td>\n",
       "      <td>0.246363</td>\n",
       "      <td>0.120704</td>\n",
       "      <td>0.254212</td>\n",
       "      <td>0.271848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0</td>\n",
       "      <td>15.357859</td>\n",
       "      <td>1.529557</td>\n",
       "      <td>2.013819</td>\n",
       "      <td>1.665785</td>\n",
       "      <td>1.214604</td>\n",
       "      <td>2.044015</td>\n",
       "      <td>2.670585</td>\n",
       "      <td>11.684998</td>\n",
       "      <td>10.602521</td>\n",
       "      <td>...</td>\n",
       "      <td>6.367861</td>\n",
       "      <td>6.452035</td>\n",
       "      <td>3.165961</td>\n",
       "      <td>5.588555</td>\n",
       "      <td>0.043673</td>\n",
       "      <td>0.052826</td>\n",
       "      <td>0.070380</td>\n",
       "      <td>0.111639</td>\n",
       "      <td>0.103519</td>\n",
       "      <td>0.072111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>902 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex        Age  eyesclosed_fband_delta_absmean_lfront  \\\n",
       "0      1   7.623203                               7.519803   \n",
       "1      0  10.835158                               2.346685   \n",
       "2      0   7.987451                               1.281869   \n",
       "3      1   8.096851                               3.109075   \n",
       "4      0   8.357061                               5.786769   \n",
       "..   ...        ...                                    ...   \n",
       "901    1   6.517796                               8.594610   \n",
       "902    0  16.456194                               7.487871   \n",
       "903    0  16.119438                               3.743134   \n",
       "904    1   7.563084                               2.830657   \n",
       "905    0  15.357859                               1.529557   \n",
       "\n",
       "     eyesclosed_fband_delta_absmean_mfront  \\\n",
       "0                                 7.043891   \n",
       "1                                 3.945786   \n",
       "2                                 1.229748   \n",
       "3                                 4.803264   \n",
       "4                                 6.818487   \n",
       "..                                     ...   \n",
       "901                              13.258798   \n",
       "902                               9.809903   \n",
       "903                               3.795633   \n",
       "904                               5.259391   \n",
       "905                               2.013819   \n",
       "\n",
       "     eyesclosed_fband_delta_absmean_rfront  \\\n",
       "0                                 6.528158   \n",
       "1                                 2.962716   \n",
       "2                                 1.905450   \n",
       "3                                 2.873502   \n",
       "4                                 6.296279   \n",
       "..                                     ...   \n",
       "901                               7.158682   \n",
       "902                               7.255467   \n",
       "903                               3.286381   \n",
       "904                               6.724664   \n",
       "905                               1.665785   \n",
       "\n",
       "     eyesclosed_fband_delta_absmean_lpari  \\\n",
       "0                                9.633529   \n",
       "1                                3.440606   \n",
       "2                                1.768091   \n",
       "3                                2.644382   \n",
       "4                                8.043145   \n",
       "..                                    ...   \n",
       "901                             12.743212   \n",
       "902                              8.731814   \n",
       "903                              2.779438   \n",
       "904                              4.745513   \n",
       "905                              1.214604   \n",
       "\n",
       "     eyesclosed_fband_delta_absmean_mpari  \\\n",
       "0                                9.989483   \n",
       "1                                3.565384   \n",
       "2                                1.484286   \n",
       "3                                3.884837   \n",
       "4                                9.413683   \n",
       "..                                    ...   \n",
       "901                              8.698643   \n",
       "902                              9.629680   \n",
       "903                              3.539956   \n",
       "904                              5.885628   \n",
       "905                              2.044015   \n",
       "\n",
       "     eyesclosed_fband_delta_absmean_rpari  \\\n",
       "0                                9.305804   \n",
       "1                                3.023286   \n",
       "2                                0.756394   \n",
       "3                                2.391569   \n",
       "4                                6.839451   \n",
       "..                                    ...   \n",
       "901                              4.855232   \n",
       "902                             11.326718   \n",
       "903                              3.800533   \n",
       "904                              3.160138   \n",
       "905                              2.670585   \n",
       "\n",
       "     eyesclosed_fband_delta_relmean_lfront  \\\n",
       "0                                 9.598653   \n",
       "1                                10.968235   \n",
       "2                                13.132905   \n",
       "3                                 9.931212   \n",
       "4                                10.495082   \n",
       "..                                     ...   \n",
       "901                              15.315470   \n",
       "902                               7.404931   \n",
       "903                               8.565498   \n",
       "904                              13.388712   \n",
       "905                              11.684998   \n",
       "\n",
       "     eyesclosed_fband_delta_relmean_mfront  ...  \\\n",
       "0                                10.164125  ...   \n",
       "1                                12.461058  ...   \n",
       "2                                11.998897  ...   \n",
       "3                                10.869944  ...   \n",
       "4                                11.095547  ...   \n",
       "..                                     ...  ...   \n",
       "901                              14.779320  ...   \n",
       "902                               7.060421  ...   \n",
       "903                               8.383859  ...   \n",
       "904                              13.121943  ...   \n",
       "905                              10.602521  ...   \n",
       "\n",
       "     eyesopen_fooof_peak_freq_rfront  eyesopen_fooof_peak_freq_lpari  \\\n",
       "0                           9.485781                        9.441022   \n",
       "1                           8.800915                        8.510134   \n",
       "2                           5.604535                        5.602136   \n",
       "3                           9.288451                        6.651558   \n",
       "4                           6.952035                        5.065536   \n",
       "..                               ...                             ...   \n",
       "901                         5.868008                       22.846455   \n",
       "902                         9.389994                        9.540163   \n",
       "903                        10.376962                       10.707490   \n",
       "904                         9.482208                        7.101976   \n",
       "905                         6.367861                        6.452035   \n",
       "\n",
       "     eyesopen_fooof_peak_freq_mpari  eyesopen_fooof_peak_freq_rpari  \\\n",
       "0                          9.384172                        9.425798   \n",
       "1                          9.078390                       14.741810   \n",
       "2                          4.096616                        5.084040   \n",
       "3                          6.396867                       10.291086   \n",
       "4                          4.679294                        4.924409   \n",
       "..                              ...                             ...   \n",
       "901                        7.050818                        4.622321   \n",
       "902                        9.482167                        9.545163   \n",
       "903                       10.383040                       10.343315   \n",
       "904                        9.409898                        9.301044   \n",
       "905                        3.165961                        5.588555   \n",
       "\n",
       "     eyesopen_fooof_peak_amplitude_lfront  \\\n",
       "0                                0.795549   \n",
       "1                                0.254701   \n",
       "2                                0.048655   \n",
       "3                                0.218827   \n",
       "4                                0.150518   \n",
       "..                                    ...   \n",
       "901                              0.416442   \n",
       "902                              1.326583   \n",
       "903                              0.623514   \n",
       "904                              0.185029   \n",
       "905                              0.043673   \n",
       "\n",
       "     eyesopen_fooof_peak_amplitude_mfront  \\\n",
       "0                                0.876262   \n",
       "1                                0.351010   \n",
       "2                                0.233294   \n",
       "3                                0.313734   \n",
       "4                                0.169058   \n",
       "..                                    ...   \n",
       "901                              0.358625   \n",
       "902                              1.288238   \n",
       "903                              0.582917   \n",
       "904                              0.165101   \n",
       "905                              0.052826   \n",
       "\n",
       "     eyesopen_fooof_peak_amplitude_rfront  \\\n",
       "0                                0.872379   \n",
       "1                                0.303875   \n",
       "2                                0.282735   \n",
       "3                                0.298905   \n",
       "4                                0.154417   \n",
       "..                                    ...   \n",
       "901                              0.380528   \n",
       "902                              1.407225   \n",
       "903                              0.422394   \n",
       "904                              0.246363   \n",
       "905                              0.070380   \n",
       "\n",
       "     eyesopen_fooof_peak_amplitude_lpari  eyesopen_fooof_peak_amplitude_mpari  \\\n",
       "0                               0.989101                             1.099981   \n",
       "1                               0.234960                             0.232564   \n",
       "2                               0.256238                             0.175123   \n",
       "3                               0.178899                             0.108880   \n",
       "4                               0.104574                             0.102992   \n",
       "..                                   ...                                  ...   \n",
       "901                             0.169463                             0.325197   \n",
       "902                             1.561878                             1.636154   \n",
       "903                             0.615360                             0.860283   \n",
       "904                             0.120704                             0.254212   \n",
       "905                             0.111639                             0.103519   \n",
       "\n",
       "     eyesopen_fooof_peak_amplitude_rpari  \n",
       "0                               0.915441  \n",
       "1                               0.344537  \n",
       "2                               0.304286  \n",
       "3                               0.449437  \n",
       "4                               0.094126  \n",
       "..                                   ...  \n",
       "901                             0.199935  \n",
       "902                             1.412149  \n",
       "903                             0.945789  \n",
       "904                             0.271848  \n",
       "905                             0.072111  \n",
       "\n",
       "[902 rows x 302 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test, y_train , y_test = train_test_split(X,Y, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  17  18\n",
      "  19  20  22  23  25  26  27  28  29  30  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  47  49  50  51  52  53  54  55  57  58  59\n",
      "  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77\n",
      "  78  79  80  81  82  83  84  85  86  87  88  89  90  92  93  94  95  97\n",
      "  98  99 100 101 102 103 104 105 106 107 108 109 110 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 150 151 152 153 154\n",
      " 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172\n",
      " 173 174 175 176 177 178 179 181 182 183 184 185 186 187 188 189 190 191\n",
      " 192 193 194 195 196 197 198 199 200 203 204 205 207 208 209 210 211 212\n",
      " 213 214 215 216 219 220 221 222 223 224 225 226 227 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 263 264 265 266 267 268 269 270\n",
      " 271 272 276 277 278 279 280 281 283 284 285 287 288 289 290 291 292 293\n",
      " 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 311 312\n",
      " 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330\n",
      " 331 332 333 335 336 337 338 339 340 341 343 344 345 346 347 348 349 350\n",
      " 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368\n",
      " 369 370 371 372 373 374 375 376 378 379 380 381 382 383 384 385 386 387\n",
      " 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 404 405 406\n",
      " 407 408 409 410 411 412 413 414 415 417 418 419 420 421 422 423 424 425\n",
      " 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444\n",
      " 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462\n",
      " 463 465 466 467 469 470 471 472 473 474 475 476 477 478 480 481 482 484\n",
      " 485 486 487 488 489 490 491 492 493 494 495 496 497 498 500 501 502 503\n",
      " 504 505 506 507 509 510 511 512 513 514 515 516 517 518 519 520 521 522\n",
      " 523 524 525 526 527 528 530 531 532 533 534 535 536 537 538 539 540 541\n",
      " 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559\n",
      " 560 561 562 563 564 566 567 568 569 571 572 573 574 575 576 577 578 579\n",
      " 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 598\n",
      " 599 600 601 602 603 604 606 607 608 609 610 611 612 613 614 615 616 617\n",
      " 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635\n",
      " 636 637 638 640 641 642 644 645 646 647 648 649 650 651 652 653 654 655\n",
      " 656 657 658 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674\n",
      " 675 676 677 678 679 680 681 682 683 684 686 687 688 689 690 691 692 693\n",
      " 694 695 696 697 698 699 700 702 704 705 706 707 708 709 710 711 714 715\n",
      " 716 717 718 719 720]\n",
      "(181, 302)\n",
      "(181, 5)\n",
      "(671, 302)\n",
      "(671, 5)\n"
     ]
    }
   ],
   "source": [
    "forest = IsolationForest()\n",
    "forest.fit(x_train)\n",
    "\n",
    "# Outlier indices for training\n",
    "outliers_training = forest.predict(x_train)\n",
    "outliers_training_indices = np.argwhere(outliers_training == 1).flatten()\n",
    "\n",
    "# Drop signal outliers in training data\n",
    "x_train = x_train[outliers_training == 1]\n",
    "y_train = y_train[outliers_training == 1]\n",
    "#x_train, y_train = drop_outliers_samples_isolation_forest(x_train, y_train)\n",
    "print(outliers_training_indices)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = pd.DataFrame(scaler.transform(x_train), columns=x_train.columns, index=x_train.index)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns, index=x_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## no need to scale y if r^2 is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset\n",
    " \n",
    "# get the model\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=n_inputs, activation='relu'))\n",
    "    model.add(Dense(50, input_dim=n_inputs, activation='relu'))\n",
    "    #model.add(Dense(50, input_dim=n_inputs, activation='relu'))\n",
    "    #model.add(Dense(50, input_dim=n_inputs, activation='relu'))\n",
    "    #model.add(Dense(50, input_dim=n_inputs, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation=None))\n",
    "    model.compile(loss='mse' , optimizer='adam')\n",
    "    return model\n",
    " \n",
    "# evaluate a model using repeated k-fold cross-validation\n",
    "def evaluate_model(X, y):\n",
    "    results = list()\n",
    "    n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "    \n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # enumerate folds\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "        # prepare data\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        # define model\n",
    "        model = get_model(n_inputs, n_outputs)\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=100)\n",
    "        # evaluate model on test set\n",
    "        mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "        # store result\n",
    "        print('>%.3f' % mae)\n",
    "    results.append(mae)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pldelacour/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/pldelacour/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 559 samples, validate on 112 samples\n",
      "Epoch 1/400\n",
      " - 0s - loss: 1372.2450 - val_loss: 1101.7588\n",
      "Epoch 2/400\n",
      " - 0s - loss: 1341.5204 - val_loss: 1075.8597\n",
      "Epoch 3/400\n",
      " - 0s - loss: 1311.6376 - val_loss: 1048.8356\n",
      "Epoch 4/400\n",
      " - 0s - loss: 1278.9439 - val_loss: 1019.3776\n",
      "Epoch 5/400\n",
      " - 0s - loss: 1243.6833 - val_loss: 987.2018\n",
      "Epoch 6/400\n",
      " - 0s - loss: 1203.8843 - val_loss: 951.3637\n",
      "Epoch 7/400\n",
      " - 0s - loss: 1159.4533 - val_loss: 911.3738\n",
      "Epoch 8/400\n",
      " - 0s - loss: 1109.2803 - val_loss: 867.3065\n",
      "Epoch 9/400\n",
      " - 0s - loss: 1053.9542 - val_loss: 819.8355\n",
      "Epoch 10/400\n",
      " - 0s - loss: 994.6954 - val_loss: 770.1048\n",
      "Epoch 11/400\n",
      " - 0s - loss: 930.6820 - val_loss: 719.3674\n",
      "Epoch 12/400\n",
      " - 0s - loss: 864.8640 - val_loss: 668.0806\n",
      "Epoch 13/400\n",
      " - 0s - loss: 798.7294 - val_loss: 619.0298\n",
      "Epoch 14/400\n",
      " - 0s - loss: 734.7571 - val_loss: 575.7750\n",
      "Epoch 15/400\n",
      " - 0s - loss: 672.9909 - val_loss: 540.5131\n",
      "Epoch 16/400\n",
      " - 0s - loss: 621.3586 - val_loss: 516.2713\n",
      "Epoch 17/400\n",
      " - 0s - loss: 580.6004 - val_loss: 504.1814\n",
      "Epoch 18/400\n",
      " - 0s - loss: 551.2263 - val_loss: 500.8387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_mse available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/400\n",
      " - 0s - loss: 536.3934 - val_loss: 500.8582\n",
      "Epoch 20/400\n",
      " - 0s - loss: 524.5161 - val_loss: 502.3167\n",
      "Epoch 21/400\n",
      " - 0s - loss: 518.5612 - val_loss: 502.5848\n",
      "Epoch 22/400\n",
      " - 0s - loss: 514.4584 - val_loss: 499.4249\n",
      "Epoch 23/400\n",
      " - 0s - loss: 509.8881 - val_loss: 491.2922\n",
      "Epoch 24/400\n",
      " - 0s - loss: 500.2398 - val_loss: 476.7938\n",
      "Epoch 25/400\n",
      " - 0s - loss: 489.4448 - val_loss: 464.2764\n",
      "Epoch 26/400\n",
      " - 0s - loss: 479.9790 - val_loss: 455.6680\n",
      "Epoch 27/400\n",
      " - 0s - loss: 473.4327 - val_loss: 449.0216\n",
      "Epoch 28/400\n",
      " - 0s - loss: 468.9505 - val_loss: 444.2231\n",
      "Epoch 29/400\n",
      " - 0s - loss: 465.3428 - val_loss: 437.9785\n",
      "Epoch 30/400\n",
      " - 0s - loss: 461.4837 - val_loss: 429.8483\n",
      "Epoch 31/400\n",
      " - 0s - loss: 457.5496 - val_loss: 421.0379\n",
      "Epoch 32/400\n",
      " - 0s - loss: 453.9374 - val_loss: 413.1442\n",
      "Epoch 33/400\n",
      " - 0s - loss: 449.8761 - val_loss: 408.5932\n",
      "Epoch 34/400\n",
      " - 0s - loss: 446.5669 - val_loss: 402.8591\n",
      "Epoch 35/400\n",
      " - 0s - loss: 443.5377 - val_loss: 396.0454\n",
      "Epoch 36/400\n",
      " - 0s - loss: 441.0527 - val_loss: 391.5456\n",
      "Epoch 37/400\n",
      " - 0s - loss: 438.2754 - val_loss: 390.1401\n",
      "Epoch 38/400\n",
      " - 0s - loss: 434.4677 - val_loss: 390.7741\n",
      "Epoch 39/400\n",
      " - 0s - loss: 431.5026 - val_loss: 391.5325\n",
      "Epoch 40/400\n",
      " - 0s - loss: 428.9136 - val_loss: 390.2731\n",
      "Epoch 41/400\n",
      " - 0s - loss: 426.3054 - val_loss: 387.0495\n",
      "Epoch 42/400\n",
      " - 0s - loss: 423.7999 - val_loss: 386.4548\n",
      "Epoch 43/400\n",
      " - 0s - loss: 421.4291 - val_loss: 387.1489\n",
      "Epoch 44/400\n",
      " - 0s - loss: 419.9431 - val_loss: 385.8562\n",
      "Epoch 45/400\n",
      " - 0s - loss: 417.7229 - val_loss: 381.7684\n",
      "Epoch 46/400\n",
      " - 0s - loss: 414.9581 - val_loss: 376.5901\n",
      "Epoch 47/400\n",
      " - 0s - loss: 412.3605 - val_loss: 371.2986\n",
      "Epoch 48/400\n",
      " - 0s - loss: 410.1569 - val_loss: 366.7763\n",
      "Epoch 49/400\n",
      " - 0s - loss: 408.0215 - val_loss: 366.9626\n",
      "Epoch 50/400\n",
      " - 0s - loss: 406.1636 - val_loss: 369.2040\n",
      "Epoch 51/400\n",
      " - 0s - loss: 404.1922 - val_loss: 371.3947\n",
      "Epoch 52/400\n",
      " - 0s - loss: 401.9499 - val_loss: 372.8510\n",
      "Epoch 53/400\n",
      " - 0s - loss: 399.6145 - val_loss: 372.8008\n",
      "Epoch 54/400\n",
      " - 0s - loss: 399.8541 - val_loss: 370.7913\n",
      "Epoch 55/400\n",
      " - 0s - loss: 399.6745 - val_loss: 367.4499\n",
      "Epoch 56/400\n",
      " - 0s - loss: 398.2381 - val_loss: 365.9463\n",
      "Epoch 57/400\n",
      " - 0s - loss: 396.8296 - val_loss: 364.2060\n",
      "Epoch 58/400\n",
      " - 0s - loss: 394.9030 - val_loss: 360.6362\n",
      "Epoch 59/400\n",
      " - 0s - loss: 392.4689 - val_loss: 356.4236\n",
      "Epoch 60/400\n",
      " - 0s - loss: 390.4969 - val_loss: 352.5536\n",
      "Epoch 61/400\n",
      " - 0s - loss: 387.4813 - val_loss: 348.1879\n",
      "Epoch 62/400\n",
      " - 0s - loss: 384.2799 - val_loss: 344.6800\n",
      "Epoch 63/400\n",
      " - 0s - loss: 381.1364 - val_loss: 341.5370\n",
      "Epoch 64/400\n",
      " - 0s - loss: 379.3491 - val_loss: 339.8393\n",
      "Epoch 65/400\n",
      " - 0s - loss: 377.9030 - val_loss: 339.4652\n",
      "Epoch 66/400\n",
      " - 0s - loss: 376.2865 - val_loss: 338.5289\n",
      "Epoch 67/400\n",
      " - 0s - loss: 375.2816 - val_loss: 335.5815\n",
      "Epoch 68/400\n",
      " - 0s - loss: 373.7312 - val_loss: 334.4717\n",
      "Epoch 69/400\n",
      " - 0s - loss: 372.2968 - val_loss: 333.7812\n",
      "Epoch 70/400\n",
      " - 0s - loss: 370.8435 - val_loss: 333.7783\n",
      "Epoch 71/400\n",
      " - 0s - loss: 369.5437 - val_loss: 334.8669\n",
      "Epoch 72/400\n",
      " - 0s - loss: 367.7460 - val_loss: 337.2769\n",
      "Epoch 73/400\n",
      " - 0s - loss: 365.0704 - val_loss: 341.5067\n",
      "Epoch 74/400\n",
      " - 0s - loss: 363.5922 - val_loss: 342.7973\n",
      "Epoch 75/400\n",
      " - 0s - loss: 362.3127 - val_loss: 342.6006\n",
      "Epoch 76/400\n",
      " - 0s - loss: 361.1262 - val_loss: 340.4570\n",
      "Epoch 77/400\n",
      " - 0s - loss: 359.3200 - val_loss: 339.9320\n",
      "Epoch 78/400\n",
      " - 0s - loss: 357.7476 - val_loss: 340.2801\n",
      "Epoch 79/400\n",
      " - 0s - loss: 356.0997 - val_loss: 340.6164\n",
      "Epoch 80/400\n",
      " - 0s - loss: 355.3989 - val_loss: 339.1297\n",
      "Epoch 81/400\n",
      " - 0s - loss: 354.6193 - val_loss: 335.0961\n",
      "Epoch 82/400\n",
      " - 0s - loss: 353.6511 - val_loss: 330.3192\n",
      "Epoch 83/400\n",
      " - 0s - loss: 351.6093 - val_loss: 328.5460\n",
      "Epoch 84/400\n",
      " - 0s - loss: 349.5123 - val_loss: 327.1234\n",
      "Epoch 85/400\n",
      " - 0s - loss: 348.0590 - val_loss: 324.3671\n",
      "Epoch 86/400\n",
      " - 0s - loss: 347.6359 - val_loss: 324.1350\n",
      "Epoch 87/400\n",
      " - 0s - loss: 347.5647 - val_loss: 324.4910\n",
      "Epoch 88/400\n",
      " - 0s - loss: 346.4515 - val_loss: 327.0445\n",
      "Epoch 89/400\n",
      " - 0s - loss: 343.5706 - val_loss: 333.3083\n",
      "Epoch 90/400\n",
      " - 0s - loss: 341.9137 - val_loss: 339.1370\n",
      "Epoch 91/400\n",
      " - 0s - loss: 340.1190 - val_loss: 343.4888\n",
      "Epoch 92/400\n",
      " - 0s - loss: 340.0594 - val_loss: 343.3246\n",
      "Epoch 93/400\n",
      " - 0s - loss: 339.2516 - val_loss: 336.5797\n",
      "Epoch 94/400\n",
      " - 0s - loss: 338.0230 - val_loss: 330.9291\n",
      "Epoch 95/400\n",
      " - 0s - loss: 336.9734 - val_loss: 328.2990\n",
      "Epoch 96/400\n",
      " - 0s - loss: 335.9483 - val_loss: 326.0281\n",
      "Epoch 97/400\n",
      " - 0s - loss: 335.1425 - val_loss: 321.3433\n",
      "Epoch 98/400\n",
      " - 0s - loss: 334.5490 - val_loss: 314.9274\n",
      "Epoch 99/400\n",
      " - 0s - loss: 334.6227 - val_loss: 309.1494\n",
      "Epoch 100/400\n",
      " - 0s - loss: 337.1676 - val_loss: 306.4117\n",
      "Epoch 101/400\n",
      " - 0s - loss: 339.2529 - val_loss: 305.7444\n",
      "Epoch 102/400\n",
      " - 0s - loss: 339.9556 - val_loss: 306.2264\n",
      "Epoch 103/400\n",
      " - 0s - loss: 339.7703 - val_loss: 306.7954\n",
      "Epoch 104/400\n",
      " - 0s - loss: 336.6535 - val_loss: 308.6664\n",
      "Epoch 105/400\n",
      " - 0s - loss: 332.2113 - val_loss: 311.1574\n",
      "Epoch 106/400\n",
      " - 0s - loss: 327.2534 - val_loss: 315.1675\n",
      "Epoch 107/400\n",
      " - 0s - loss: 324.9000 - val_loss: 321.7811\n",
      "Epoch 108/400\n",
      " - 0s - loss: 322.1273 - val_loss: 330.8336\n",
      "Epoch 109/400\n",
      " - 0s - loss: 321.9842 - val_loss: 337.0202\n",
      "Epoch 110/400\n",
      " - 0s - loss: 322.3624 - val_loss: 338.0902\n",
      "Epoch 111/400\n",
      " - 0s - loss: 322.2002 - val_loss: 335.4796\n",
      "Epoch 112/400\n",
      " - 0s - loss: 322.3720 - val_loss: 331.7754\n",
      "Epoch 113/400\n",
      " - 0s - loss: 321.0840 - val_loss: 325.0651\n",
      "Epoch 114/400\n",
      " - 0s - loss: 318.7754 - val_loss: 317.6438\n",
      "Epoch 115/400\n",
      " - 0s - loss: 317.8523 - val_loss: 314.6457\n",
      "Epoch 116/400\n",
      " - 0s - loss: 317.2240 - val_loss: 314.8195\n",
      "Epoch 117/400\n",
      " - 0s - loss: 316.7983 - val_loss: 314.7507\n",
      "Epoch 118/400\n",
      " - 0s - loss: 316.3971 - val_loss: 314.0862\n",
      "Epoch 119/400\n",
      " - 0s - loss: 315.1905 - val_loss: 314.4136\n",
      "Epoch 120/400\n",
      " - 0s - loss: 313.4154 - val_loss: 314.8538\n",
      "Epoch 121/400\n",
      " - 0s - loss: 312.0924 - val_loss: 315.4274\n",
      "Epoch 122/400\n",
      " - 0s - loss: 310.7437 - val_loss: 315.9440\n",
      "Epoch 123/400\n",
      " - 0s - loss: 310.1210 - val_loss: 316.0409\n",
      "Epoch 124/400\n",
      " - 0s - loss: 309.4471 - val_loss: 317.5971\n",
      "Epoch 125/400\n",
      " - 0s - loss: 308.5023 - val_loss: 321.0663\n",
      "Epoch 126/400\n",
      " - 0s - loss: 307.5928 - val_loss: 328.2032\n",
      "Epoch 127/400\n",
      " - 0s - loss: 307.6851 - val_loss: 335.6822\n",
      "Epoch 128/400\n",
      " - 0s - loss: 307.2754 - val_loss: 337.1250\n",
      "Epoch 129/400\n",
      " - 0s - loss: 306.3477 - val_loss: 338.2409\n",
      "Epoch 130/400\n",
      " - 0s - loss: 304.1653 - val_loss: 341.0049\n",
      "Epoch 131/400\n",
      " - 0s - loss: 302.5093 - val_loss: 341.7486\n",
      "Epoch 132/400\n",
      " - 0s - loss: 301.9752 - val_loss: 337.6958\n",
      "Epoch 133/400\n",
      " - 0s - loss: 301.1005 - val_loss: 334.0567\n",
      "Epoch 134/400\n",
      " - 0s - loss: 300.0138 - val_loss: 333.7289\n",
      "Epoch 135/400\n",
      " - 0s - loss: 299.2855 - val_loss: 338.4002\n",
      "Epoch 136/400\n",
      " - 0s - loss: 300.3152 - val_loss: 347.5027\n",
      "Epoch 137/400\n",
      " - 0s - loss: 303.1612 - val_loss: 355.3867\n",
      "Epoch 138/400\n",
      " - 0s - loss: 304.2791 - val_loss: 356.9966\n",
      "Epoch 139/400\n",
      " - 0s - loss: 303.7071 - val_loss: 356.5357\n",
      "Epoch 140/400\n",
      " - 0s - loss: 301.9113 - val_loss: 348.7354\n",
      "Epoch 141/400\n",
      " - 0s - loss: 298.3928 - val_loss: 338.5923\n",
      "Epoch 142/400\n",
      " - 0s - loss: 295.3364 - val_loss: 331.2569\n",
      "Epoch 143/400\n",
      " - 0s - loss: 292.6102 - val_loss: 328.3048\n",
      "Epoch 144/400\n",
      " - 0s - loss: 291.9110 - val_loss: 327.4843\n",
      "Epoch 145/400\n",
      " - 0s - loss: 293.1421 - val_loss: 329.1364\n",
      "Epoch 146/400\n",
      " - 0s - loss: 293.0439 - val_loss: 334.3936\n",
      "Epoch 147/400\n",
      " - 0s - loss: 291.9999 - val_loss: 342.4428\n",
      "Epoch 148/400\n",
      " - 0s - loss: 291.5405 - val_loss: 349.0659\n",
      "Epoch 149/400\n",
      " - 0s - loss: 291.7834 - val_loss: 354.9429\n",
      "Epoch 150/400\n",
      " - 0s - loss: 293.0004 - val_loss: 357.6155\n",
      "Epoch 151/400\n",
      " - 0s - loss: 291.9721 - val_loss: 353.4919\n",
      "Epoch 152/400\n",
      " - 0s - loss: 288.8638 - val_loss: 344.7041\n",
      "Epoch 153/400\n",
      " - 0s - loss: 287.0048 - val_loss: 341.5062\n",
      "Epoch 154/400\n",
      " - 0s - loss: 286.3345 - val_loss: 342.3976\n",
      "Epoch 155/400\n",
      " - 0s - loss: 285.4439 - val_loss: 339.2021\n",
      "Epoch 156/400\n",
      " - 0s - loss: 283.8994 - val_loss: 335.5913\n",
      "Epoch 157/400\n",
      " - 0s - loss: 283.1261 - val_loss: 338.1547\n",
      "Epoch 158/400\n",
      " - 0s - loss: 283.7797 - val_loss: 341.7459\n",
      "Epoch 159/400\n",
      " - 0s - loss: 285.2239 - val_loss: 343.8844\n",
      "Epoch 160/400\n",
      " - 0s - loss: 285.5565 - val_loss: 346.3796\n",
      "Epoch 161/400\n",
      " - 0s - loss: 285.0371 - val_loss: 349.1833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/400\n",
      " - 0s - loss: 283.5443 - val_loss: 352.4851\n",
      "Epoch 163/400\n",
      " - 0s - loss: 281.9342 - val_loss: 359.9262\n",
      "Epoch 164/400\n",
      " - 0s - loss: 281.1853 - val_loss: 369.1436\n",
      "Epoch 165/400\n",
      " - 0s - loss: 281.4882 - val_loss: 375.3300\n",
      "Epoch 166/400\n",
      " - 0s - loss: 282.4066 - val_loss: 368.9834\n",
      "Epoch 167/400\n",
      " - 0s - loss: 280.5700 - val_loss: 358.0044\n",
      "Epoch 168/400\n",
      " - 0s - loss: 279.5047 - val_loss: 353.8977\n",
      "Epoch 169/400\n",
      " - 0s - loss: 278.9252 - val_loss: 356.5669\n",
      "Epoch 170/400\n",
      " - 0s - loss: 278.5712 - val_loss: 356.4060\n",
      "Epoch 171/400\n",
      " - 0s - loss: 276.1298 - val_loss: 351.2411\n",
      "Epoch 172/400\n",
      " - 0s - loss: 274.6582 - val_loss: 347.5644\n",
      "Epoch 173/400\n",
      " - 0s - loss: 274.3978 - val_loss: 345.6131\n",
      "Epoch 174/400\n",
      " - 0s - loss: 273.5814 - val_loss: 344.5486\n",
      "Epoch 175/400\n",
      " - 0s - loss: 273.3110 - val_loss: 343.0732\n",
      "Epoch 176/400\n",
      " - 0s - loss: 273.0026 - val_loss: 343.0625\n",
      "Epoch 177/400\n",
      " - 0s - loss: 271.2460 - val_loss: 347.3772\n",
      "Epoch 178/400\n",
      " - 0s - loss: 269.5209 - val_loss: 363.7804\n",
      "Epoch 179/400\n",
      " - 0s - loss: 271.5360 - val_loss: 379.2238\n",
      "Epoch 180/400\n",
      " - 0s - loss: 272.8704 - val_loss: 384.1810\n",
      "Epoch 181/400\n",
      " - 0s - loss: 273.5697 - val_loss: 383.1359\n",
      "Epoch 182/400\n",
      " - 0s - loss: 272.7150 - val_loss: 371.4494\n",
      "Epoch 183/400\n",
      " - 0s - loss: 271.0430 - val_loss: 362.6889\n",
      "Epoch 184/400\n",
      " - 0s - loss: 268.3691 - val_loss: 357.3559\n",
      "Epoch 185/400\n",
      " - 0s - loss: 265.4448 - val_loss: 359.1818\n",
      "Epoch 186/400\n",
      " - 0s - loss: 263.7041 - val_loss: 363.6299\n",
      "Epoch 187/400\n",
      " - 0s - loss: 264.2793 - val_loss: 365.7568\n",
      "Epoch 188/400\n",
      " - 0s - loss: 264.7817 - val_loss: 368.0896\n",
      "Epoch 189/400\n",
      " - 0s - loss: 264.0990 - val_loss: 367.6035\n",
      "Epoch 190/400\n",
      " - 0s - loss: 263.3112 - val_loss: 367.3746\n",
      "Epoch 191/400\n",
      " - 0s - loss: 262.0744 - val_loss: 367.7651\n",
      "Epoch 192/400\n",
      " - 0s - loss: 262.2094 - val_loss: 367.5172\n",
      "Epoch 193/400\n",
      " - 0s - loss: 263.4624 - val_loss: 366.0803\n",
      "Epoch 194/400\n",
      " - 0s - loss: 263.2994 - val_loss: 364.4402\n",
      "Epoch 195/400\n",
      " - 0s - loss: 263.5935 - val_loss: 363.6966\n",
      "Epoch 196/400\n",
      " - 0s - loss: 263.7550 - val_loss: 362.8047\n",
      "Epoch 197/400\n",
      " - 0s - loss: 260.8067 - val_loss: 363.7917\n",
      "Epoch 198/400\n",
      " - 0s - loss: 257.6438 - val_loss: 369.8812\n",
      "Epoch 199/400\n",
      " - 0s - loss: 258.9468 - val_loss: 371.9467\n",
      "Epoch 200/400\n",
      " - 0s - loss: 260.5326 - val_loss: 372.2107\n",
      "Epoch 201/400\n",
      " - 0s - loss: 259.9055 - val_loss: 373.6444\n",
      "Epoch 202/400\n",
      " - 0s - loss: 258.0475 - val_loss: 371.1134\n",
      "Epoch 203/400\n",
      " - 0s - loss: 255.3431 - val_loss: 362.4640\n",
      "Epoch 204/400\n",
      " - 0s - loss: 253.3332 - val_loss: 353.0130\n",
      "Epoch 205/400\n",
      " - 0s - loss: 252.3149 - val_loss: 348.8834\n",
      "Epoch 206/400\n",
      " - 0s - loss: 251.5635 - val_loss: 352.6353\n",
      "Epoch 207/400\n",
      " - 0s - loss: 250.6900 - val_loss: 360.9191\n",
      "Epoch 208/400\n",
      " - 0s - loss: 249.9510 - val_loss: 364.8175\n",
      "Epoch 209/400\n",
      " - 0s - loss: 250.0671 - val_loss: 367.3159\n",
      "Epoch 210/400\n",
      " - 0s - loss: 249.9077 - val_loss: 366.6486\n",
      "Epoch 211/400\n",
      " - 0s - loss: 248.3262 - val_loss: 356.7112\n",
      "Epoch 212/400\n",
      " - 0s - loss: 249.2581 - val_loss: 352.6526\n",
      "Epoch 213/400\n",
      " - 0s - loss: 250.8469 - val_loss: 352.7221\n",
      "Epoch 214/400\n",
      " - 0s - loss: 252.3418 - val_loss: 351.8612\n",
      "Epoch 215/400\n",
      " - 0s - loss: 253.3206 - val_loss: 347.7339\n",
      "Epoch 216/400\n",
      " - 0s - loss: 252.9960 - val_loss: 345.7559\n",
      "Epoch 217/400\n",
      " - 0s - loss: 252.7516 - val_loss: 345.4965\n",
      "Epoch 218/400\n",
      " - 0s - loss: 252.0595 - val_loss: 353.5484\n",
      "Epoch 219/400\n",
      " - 0s - loss: 250.8118 - val_loss: 363.1023\n",
      "Epoch 220/400\n",
      " - 0s - loss: 250.8530 - val_loss: 364.9710\n",
      "Epoch 221/400\n",
      " - 0s - loss: 249.8442 - val_loss: 359.0185\n",
      "Epoch 222/400\n",
      " - 0s - loss: 247.7893 - val_loss: 357.3589\n",
      "Epoch 223/400\n",
      " - 0s - loss: 247.8998 - val_loss: 357.2204\n",
      "Epoch 224/400\n",
      " - 0s - loss: 247.6807 - val_loss: 356.4429\n",
      "Epoch 225/400\n",
      " - 0s - loss: 246.5510 - val_loss: 356.4525\n",
      "Epoch 226/400\n",
      " - 0s - loss: 245.5720 - val_loss: 358.2412\n",
      "Epoch 227/400\n",
      " - 0s - loss: 243.9303 - val_loss: 361.1774\n",
      "Epoch 228/400\n",
      " - 0s - loss: 242.0061 - val_loss: 362.2232\n",
      "Epoch 229/400\n",
      " - 0s - loss: 240.7590 - val_loss: 359.6205\n",
      "Epoch 230/400\n",
      " - 0s - loss: 240.2324 - val_loss: 359.8295\n",
      "Epoch 231/400\n",
      " - 0s - loss: 238.4653 - val_loss: 361.4754\n",
      "Epoch 232/400\n",
      " - 0s - loss: 237.3258 - val_loss: 362.8360\n",
      "Epoch 233/400\n",
      " - 0s - loss: 236.6903 - val_loss: 360.7199\n",
      "Epoch 234/400\n",
      " - 0s - loss: 236.6393 - val_loss: 362.5677\n",
      "Epoch 235/400\n",
      " - 0s - loss: 236.1031 - val_loss: 368.1521\n",
      "Epoch 236/400\n",
      " - 0s - loss: 235.0265 - val_loss: 372.7046\n",
      "Epoch 237/400\n",
      " - 0s - loss: 234.9648 - val_loss: 373.2536\n",
      "Epoch 238/400\n",
      " - 0s - loss: 235.2690 - val_loss: 370.9438\n",
      "Epoch 239/400\n",
      " - 0s - loss: 234.4304 - val_loss: 371.0996\n",
      "Epoch 240/400\n",
      " - 0s - loss: 233.6426 - val_loss: 377.6345\n",
      "Epoch 241/400\n",
      " - 0s - loss: 233.5098 - val_loss: 377.0055\n",
      "Epoch 242/400\n",
      " - 0s - loss: 232.5831 - val_loss: 370.5129\n",
      "Epoch 243/400\n",
      " - 0s - loss: 232.1174 - val_loss: 364.1077\n",
      "Epoch 244/400\n",
      " - 0s - loss: 231.8050 - val_loss: 362.9174\n",
      "Epoch 245/400\n",
      " - 0s - loss: 230.9742 - val_loss: 366.2054\n",
      "Epoch 246/400\n",
      " - 0s - loss: 229.9146 - val_loss: 376.0240\n",
      "Epoch 247/400\n",
      " - 0s - loss: 230.6457 - val_loss: 383.8789\n",
      "Epoch 248/400\n",
      " - 0s - loss: 232.9951 - val_loss: 394.0770\n",
      "Epoch 249/400\n",
      " - 0s - loss: 233.9200 - val_loss: 395.6186\n",
      "Epoch 250/400\n",
      " - 0s - loss: 231.2156 - val_loss: 391.1552\n",
      "Epoch 251/400\n",
      " - 0s - loss: 228.7557 - val_loss: 388.4328\n",
      "Epoch 252/400\n",
      " - 0s - loss: 227.4859 - val_loss: 382.6909\n",
      "Epoch 253/400\n",
      " - 0s - loss: 225.9016 - val_loss: 374.7880\n",
      "Epoch 254/400\n",
      " - 0s - loss: 224.9598 - val_loss: 371.8524\n",
      "Epoch 255/400\n",
      " - 0s - loss: 223.8549 - val_loss: 373.7378\n",
      "Epoch 256/400\n",
      " - 0s - loss: 223.2688 - val_loss: 374.4709\n",
      "Epoch 257/400\n",
      " - 0s - loss: 223.2671 - val_loss: 368.7983\n",
      "Epoch 258/400\n",
      " - 0s - loss: 223.3970 - val_loss: 360.5862\n",
      "Epoch 259/400\n",
      " - 0s - loss: 223.5083 - val_loss: 359.2530\n",
      "Epoch 260/400\n",
      " - 0s - loss: 223.8649 - val_loss: 365.5514\n",
      "Epoch 261/400\n",
      " - 0s - loss: 221.4148 - val_loss: 385.7910\n",
      "Epoch 262/400\n",
      " - 0s - loss: 222.0960 - val_loss: 402.1002\n",
      "Epoch 263/400\n",
      " - 0s - loss: 224.2885 - val_loss: 407.6306\n",
      "Epoch 264/400\n",
      " - 0s - loss: 226.4600 - val_loss: 409.2405\n",
      "Epoch 265/400\n",
      " - 0s - loss: 227.3373 - val_loss: 409.8230\n",
      "Epoch 266/400\n",
      " - 0s - loss: 226.5491 - val_loss: 404.4417\n",
      "Epoch 267/400\n",
      " - 0s - loss: 225.0049 - val_loss: 395.5416\n",
      "Epoch 268/400\n",
      " - 0s - loss: 222.3316 - val_loss: 381.0950\n",
      "Epoch 269/400\n",
      " - 0s - loss: 222.2385 - val_loss: 368.6397\n",
      "Epoch 270/400\n",
      " - 0s - loss: 225.2506 - val_loss: 361.6645\n",
      "Epoch 271/400\n",
      " - 0s - loss: 227.7915 - val_loss: 357.1894\n",
      "Epoch 272/400\n",
      " - 0s - loss: 227.4227 - val_loss: 355.6552\n",
      "Epoch 273/400\n",
      " - 0s - loss: 225.5259 - val_loss: 358.8155\n",
      "Epoch 274/400\n",
      " - 0s - loss: 222.8072 - val_loss: 364.7055\n",
      "Epoch 275/400\n",
      " - 0s - loss: 218.8612 - val_loss: 370.3225\n",
      "Epoch 276/400\n",
      " - 0s - loss: 216.0411 - val_loss: 375.2886\n",
      "Epoch 277/400\n",
      " - 0s - loss: 218.4236 - val_loss: 376.9638\n",
      "Epoch 278/400\n",
      " - 0s - loss: 224.8436 - val_loss: 380.6113\n",
      "Epoch 279/400\n",
      " - 0s - loss: 223.4432 - val_loss: 384.7610\n",
      "Epoch 280/400\n",
      " - 0s - loss: 217.2437 - val_loss: 394.9817\n",
      "Epoch 281/400\n",
      " - 0s - loss: 213.7096 - val_loss: 400.5972\n",
      "Epoch 282/400\n",
      " - 0s - loss: 212.6973 - val_loss: 387.5132\n",
      "Epoch 283/400\n",
      " - 0s - loss: 210.5913 - val_loss: 375.8248\n",
      "Epoch 284/400\n",
      " - 0s - loss: 210.8394 - val_loss: 373.4823\n",
      "Epoch 285/400\n",
      " - 0s - loss: 210.5197 - val_loss: 380.2811\n",
      "Epoch 286/400\n",
      " - 0s - loss: 209.9444 - val_loss: 385.9339\n",
      "Epoch 287/400\n",
      " - 0s - loss: 209.7567 - val_loss: 387.4681\n",
      "Epoch 288/400\n",
      " - 0s - loss: 208.8364 - val_loss: 382.1034\n",
      "Epoch 289/400\n",
      " - 0s - loss: 207.6220 - val_loss: 371.8219\n",
      "Epoch 290/400\n",
      " - 0s - loss: 207.6617 - val_loss: 364.4062\n",
      "Epoch 291/400\n",
      " - 0s - loss: 208.9137 - val_loss: 362.5852\n",
      "Epoch 292/400\n",
      " - 0s - loss: 209.8105 - val_loss: 370.6502\n",
      "Epoch 293/400\n",
      " - 0s - loss: 209.6589 - val_loss: 379.3215\n",
      "Epoch 294/400\n",
      " - 0s - loss: 210.9896 - val_loss: 393.8206\n",
      "Epoch 295/400\n",
      " - 0s - loss: 212.6347 - val_loss: 400.3652\n",
      "Epoch 296/400\n",
      " - 0s - loss: 212.2501 - val_loss: 391.7144\n",
      "Epoch 297/400\n",
      " - 0s - loss: 208.3862 - val_loss: 376.4597\n",
      "Epoch 298/400\n",
      " - 0s - loss: 204.6533 - val_loss: 363.8034\n",
      "Epoch 299/400\n",
      " - 0s - loss: 207.3508 - val_loss: 358.0370\n",
      "Epoch 300/400\n",
      " - 0s - loss: 213.3142 - val_loss: 358.1513\n",
      "Epoch 301/400\n",
      " - 0s - loss: 215.1886 - val_loss: 365.4279\n",
      "Epoch 302/400\n",
      " - 0s - loss: 209.4831 - val_loss: 381.0417\n",
      "Epoch 303/400\n",
      " - 0s - loss: 203.5514 - val_loss: 396.0061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/400\n",
      " - 0s - loss: 203.5755 - val_loss: 398.6825\n",
      "Epoch 305/400\n",
      " - 0s - loss: 201.9635 - val_loss: 388.7003\n",
      "Epoch 306/400\n",
      " - 0s - loss: 200.8857 - val_loss: 381.5177\n",
      "Epoch 307/400\n",
      " - 0s - loss: 200.3825 - val_loss: 387.5443\n",
      "Epoch 308/400\n",
      " - 0s - loss: 200.3216 - val_loss: 393.9605\n",
      "Epoch 309/400\n",
      " - 0s - loss: 200.9930 - val_loss: 394.5609\n",
      "Epoch 310/400\n",
      " - 0s - loss: 200.7118 - val_loss: 396.2117\n",
      "Epoch 311/400\n",
      " - 0s - loss: 200.1432 - val_loss: 395.9118\n",
      "Epoch 312/400\n",
      " - 0s - loss: 199.2199 - val_loss: 382.8682\n",
      "Epoch 313/400\n",
      " - 0s - loss: 198.4515 - val_loss: 371.5593\n",
      "Epoch 314/400\n",
      " - 0s - loss: 199.8576 - val_loss: 367.5427\n",
      "Epoch 315/400\n",
      " - 0s - loss: 201.4290 - val_loss: 370.3184\n",
      "Epoch 316/400\n",
      " - 0s - loss: 200.8277 - val_loss: 377.9917\n",
      "Epoch 317/400\n",
      " - 0s - loss: 198.3775 - val_loss: 381.9850\n",
      "Epoch 318/400\n",
      " - 0s - loss: 196.9499 - val_loss: 388.0049\n",
      "Epoch 319/400\n",
      " - 0s - loss: 196.0676 - val_loss: 386.2493\n",
      "Epoch 320/400\n",
      " - 0s - loss: 194.8942 - val_loss: 372.9450\n",
      "Epoch 321/400\n",
      " - 0s - loss: 194.4997 - val_loss: 369.3411\n",
      "Epoch 322/400\n",
      " - 0s - loss: 194.4527 - val_loss: 370.0174\n",
      "Epoch 323/400\n",
      " - 0s - loss: 194.8314 - val_loss: 374.3903\n",
      "Epoch 324/400\n",
      " - 0s - loss: 195.1161 - val_loss: 382.1094\n",
      "Epoch 325/400\n",
      " - 0s - loss: 194.1425 - val_loss: 390.1775\n",
      "Epoch 326/400\n",
      " - 0s - loss: 192.2212 - val_loss: 393.5975\n",
      "Epoch 327/400\n",
      " - 0s - loss: 191.3504 - val_loss: 400.1126\n",
      "Epoch 328/400\n",
      " - 0s - loss: 192.0839 - val_loss: 411.8469\n",
      "Epoch 329/400\n",
      " - 0s - loss: 193.9810 - val_loss: 422.4479\n",
      "Epoch 330/400\n",
      " - 0s - loss: 194.7798 - val_loss: 430.1880\n",
      "Epoch 331/400\n",
      " - 0s - loss: 194.9882 - val_loss: 420.5872\n",
      "Epoch 332/400\n",
      " - 0s - loss: 190.3125 - val_loss: 398.0041\n",
      "Epoch 333/400\n",
      " - 0s - loss: 187.9168 - val_loss: 381.2957\n",
      "Epoch 334/400\n",
      " - 0s - loss: 190.7073 - val_loss: 370.9971\n",
      "Epoch 335/400\n",
      " - 0s - loss: 196.9008 - val_loss: 366.3618\n",
      "Epoch 336/400\n",
      " - 0s - loss: 200.2905 - val_loss: 365.4122\n",
      "Epoch 337/400\n",
      " - 0s - loss: 196.5490 - val_loss: 370.3299\n",
      "Epoch 338/400\n",
      " - 0s - loss: 191.8825 - val_loss: 377.8577\n",
      "Epoch 339/400\n",
      " - 0s - loss: 186.5781 - val_loss: 387.0553\n",
      "Epoch 340/400\n",
      " - 0s - loss: 181.9911 - val_loss: 396.2947\n",
      "Epoch 341/400\n",
      " - 0s - loss: 181.1054 - val_loss: 404.2026\n",
      "Epoch 342/400\n",
      " - 0s - loss: 181.7802 - val_loss: 421.4084\n",
      "Epoch 343/400\n",
      " - 0s - loss: 187.9470 - val_loss: 440.6731\n",
      "Epoch 344/400\n",
      " - 0s - loss: 191.4407 - val_loss: 423.5404\n",
      "Epoch 345/400\n",
      " - 0s - loss: 187.7564 - val_loss: 400.7365\n",
      "Epoch 346/400\n",
      " - 0s - loss: 185.2639 - val_loss: 387.6688\n",
      "Epoch 347/400\n",
      " - 0s - loss: 184.0699 - val_loss: 385.3265\n",
      "Epoch 348/400\n",
      " - 0s - loss: 181.5189 - val_loss: 393.3718\n",
      "Epoch 349/400\n",
      " - 0s - loss: 179.1576 - val_loss: 404.3751\n",
      "Epoch 350/400\n",
      " - 0s - loss: 179.3494 - val_loss: 413.4924\n",
      "Epoch 351/400\n",
      " - 0s - loss: 180.6618 - val_loss: 420.5506\n",
      "Epoch 352/400\n",
      " - 0s - loss: 180.0766 - val_loss: 422.5540\n",
      "Epoch 353/400\n",
      " - 0s - loss: 179.3472 - val_loss: 421.2676\n",
      "Epoch 354/400\n",
      " - 0s - loss: 178.9807 - val_loss: 409.4688\n",
      "Epoch 355/400\n",
      " - 0s - loss: 176.9295 - val_loss: 390.7837\n",
      "Epoch 356/400\n",
      " - 0s - loss: 176.7847 - val_loss: 378.5861\n",
      "Epoch 357/400\n",
      " - 0s - loss: 178.4573 - val_loss: 378.1126\n",
      "Epoch 358/400\n",
      " - 0s - loss: 178.7493 - val_loss: 379.8214\n",
      "Epoch 359/400\n",
      " - 0s - loss: 180.2985 - val_loss: 383.5730\n",
      "Epoch 360/400\n",
      " - 0s - loss: 180.4639 - val_loss: 398.0051\n",
      "Epoch 361/400\n",
      " - 0s - loss: 179.4150 - val_loss: 407.0141\n",
      "Epoch 362/400\n",
      " - 0s - loss: 176.2631 - val_loss: 405.2306\n",
      "Epoch 363/400\n",
      " - 0s - loss: 173.4464 - val_loss: 402.0051\n",
      "Epoch 364/400\n",
      " - 0s - loss: 171.7388 - val_loss: 406.0960\n",
      "Epoch 365/400\n",
      " - 0s - loss: 170.6965 - val_loss: 404.5820\n",
      "Epoch 366/400\n",
      " - 0s - loss: 169.6121 - val_loss: 398.7044\n",
      "Epoch 367/400\n",
      " - 0s - loss: 170.1890 - val_loss: 395.3520\n",
      "Epoch 368/400\n",
      " - 0s - loss: 172.0353 - val_loss: 386.0480\n",
      "Epoch 369/400\n",
      " - 0s - loss: 174.6924 - val_loss: 377.0035\n",
      "Epoch 370/400\n",
      " - 0s - loss: 176.7371 - val_loss: 377.7283\n",
      "Epoch 371/400\n",
      " - 0s - loss: 171.4091 - val_loss: 395.2048\n",
      "Epoch 372/400\n",
      " - 0s - loss: 167.8203 - val_loss: 419.4963\n",
      "Epoch 373/400\n",
      " - 0s - loss: 172.4292 - val_loss: 427.5987\n",
      "Epoch 374/400\n",
      " - 0s - loss: 174.4400 - val_loss: 420.0770\n",
      "Epoch 375/400\n",
      " - 0s - loss: 171.2655 - val_loss: 403.6236\n",
      "Epoch 376/400\n",
      " - 0s - loss: 171.5287 - val_loss: 392.5005\n",
      "Epoch 377/400\n",
      " - 0s - loss: 172.9634 - val_loss: 389.5078\n",
      "Epoch 378/400\n",
      " - 0s - loss: 169.9404 - val_loss: 391.5938\n",
      "Epoch 379/400\n",
      " - 0s - loss: 166.5548 - val_loss: 395.3613\n",
      "Epoch 380/400\n",
      " - 0s - loss: 164.6057 - val_loss: 405.3357\n",
      "Epoch 381/400\n",
      " - 0s - loss: 163.6301 - val_loss: 414.1878\n",
      "Epoch 382/400\n",
      " - 0s - loss: 162.7075 - val_loss: 414.3090\n",
      "Epoch 383/400\n",
      " - 0s - loss: 161.3123 - val_loss: 411.3564\n",
      "Epoch 384/400\n",
      " - 0s - loss: 161.4007 - val_loss: 415.3684\n",
      "Epoch 385/400\n",
      " - 0s - loss: 160.6285 - val_loss: 423.2853\n",
      "Epoch 386/400\n",
      " - 0s - loss: 160.2859 - val_loss: 433.3289\n",
      "Epoch 387/400\n",
      " - 0s - loss: 160.7092 - val_loss: 437.6514\n",
      "Epoch 388/400\n",
      " - 0s - loss: 160.4440 - val_loss: 438.6895\n",
      "Epoch 389/400\n",
      " - 0s - loss: 160.6988 - val_loss: 455.6402\n",
      "Epoch 390/400\n",
      " - 0s - loss: 163.6950 - val_loss: 467.1053\n",
      "Epoch 391/400\n",
      " - 0s - loss: 166.2839 - val_loss: 452.1371\n",
      "Epoch 392/400\n",
      " - 0s - loss: 161.5976 - val_loss: 428.8108\n",
      "Epoch 393/400\n",
      " - 0s - loss: 157.6017 - val_loss: 410.6297\n",
      "Epoch 394/400\n",
      " - 0s - loss: 155.8224 - val_loss: 399.6400\n",
      "Epoch 395/400\n",
      " - 0s - loss: 157.9415 - val_loss: 397.9129\n",
      "Epoch 396/400\n",
      " - 0s - loss: 156.8695 - val_loss: 407.7261\n",
      "Epoch 397/400\n",
      " - 0s - loss: 153.6864 - val_loss: 421.8913\n",
      "Epoch 398/400\n",
      " - 0s - loss: 153.8864 - val_loss: 426.4500\n",
      "Epoch 399/400\n",
      " - 0s - loss: 153.6030 - val_loss: 427.9004\n",
      "Epoch 400/400\n",
      " - 0s - loss: 153.4711 - val_loss: 449.0034\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='Best_model.h5', monitor='val_mse', verbose=1, save_best_only=True)\n",
    "model = get_model(x_train.shape[1] , y_train.shape[1])\n",
    "file_path = \"best_model.h5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='mse', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "###\n",
    "early = EarlyStopping(monitor=\"mse\", mode=\"max\", patience=10, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"mse\", mode=\"max\", patience=3, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early\n",
    "###\n",
    "hist = model.fit(\n",
    "    x_train.to_numpy(), \n",
    "    y_train.to_numpy(), \n",
    "    validation_split = 1/6,\n",
    "    batch_size=275, epochs=400, verbose=2, shuffle=True, \n",
    "    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R^2 error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SWAN_IN_Avg</th>\n",
       "      <th>SWAN_HY_Avg</th>\n",
       "      <th>SRS_Total</th>\n",
       "      <th>SRS_RRB</th>\n",
       "      <th>SRS_SCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.888888</td>\n",
       "      <td>1.666666</td>\n",
       "      <td>89.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>85.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1.555555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>94.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.555555</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>1.666666</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>95.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>121.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>2.444444</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>-1.666666</td>\n",
       "      <td>-1.222222</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SWAN_IN_Avg  SWAN_HY_Avg  SRS_Total  SRS_RRB  SRS_SCI\n",
       "85      0.888888     1.666666       89.0     20.0     69.0\n",
       "369     1.111111     0.666666       85.0     22.0     63.0\n",
       "75      1.555555     0.000000       34.0      9.0     25.0\n",
       "501     2.333333     1.444444       94.0     17.0     77.0\n",
       "731     1.222222     0.555555       72.0     15.0     57.0\n",
       "..           ...          ...        ...      ...      ...\n",
       "839     1.666666     1.111111       95.0     18.0     77.0\n",
       "192     0.666666     0.666666      121.0     30.0     91.0\n",
       "632     0.222222     0.222222       60.0     12.0     48.0\n",
       "562     2.444444    -2.000000       31.0      8.0     23.0\n",
       "687    -1.666666    -1.222222        6.0      2.0      4.0\n",
       "\n",
       "[671 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(X , Y):\n",
    "    y_pred = model.predict(X)\n",
    "    r2_0 = r2_score(Y[:,0] , y_pred[:,0])\n",
    "    r2_1 = r2_score(Y[:,1] , y_pred[:,1])\n",
    "    r2_2 = r2_score(Y[:,2] ,y_pred[:,2])\n",
    "    r2_3 = r2_score(Y[:,3] , y_pred[:,3])\n",
    "    r2_4 = r2_score(Y[:,4] ,y_pred[:,4])\n",
    "    return (r2_0, r2_1, r2_2, r2_3 , r2_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05459268944104356 0.042021334438438473 0.4093362573153707 0.3632251254714307 0.3999559590534387\n"
     ]
    }
   ],
   "source": [
    "# Train \n",
    "r2_SWAN_IN , r2_SWAN_HY , r2_SRS_Tot , r2_SRS_RRB , r2_srs_SCI = r2(x_train ,y_train.to_numpy() )\n",
    "print(r2_SWAN_IN , r2_SWAN_HY , r2_SRS_Tot , r2_SRS_RRB ,r2_srs_SCI )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd4d9a19630>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAETCAYAAADah9Z7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd8FVX6/983N/UmpAAhhdDBkSpFoigiiLKuYgHLDwR7W9e6uzZWXXF1V1EsWBf16yorwqpYFtRVFlBAgWBATUCGlgAphAAppLf7++MmIffOOTczuZUwn9fLl9yTuWfOzJ15zlM/j8Vut2PChAkTJk4OhAR6ASZMmDBhwn8whb4JEyZMnEQwhb4JEyZMnEQwhb4JEyZMnEQwhb4JEyZMnEQwhb4JEyZMnEQwhb4JEyZMnEQIDfQCTJy4UBSlL7AHyGozbAEWqKr6jodzrwA+VlX1XUVRfgImqqpaKjk2DvhUVdXzmj+7Pd7gOkYCy4BS4ApVVXM7OM/FwKOADcd7tw34o6qqeYqi7AAeUlX18+ZjfwP8F7hdVdU3m8fSgf8AKaqq2pvHlgHnAr1VVa1qc65cYJ2qqte2GTsdx/3s2846bwCuVFV1avO/3wDGqqqa3eaY1t+mI/fCRGBhavomPEW1qqojW/4DLgKeVxRlhLdO0Dy3OwGeAKQbON4ILgXWqKo6xgOBnwq8B8xQVfU0VVWHAj8DHzYf8hUwqc1XpgLLgcvajJ0HfNlG4KcCE4CNwHWC016lKMrsjqzXBRZgiaIokV6Yy0QQwNT0TXgVqqrmK4qyCzhFUZTRwM1ANFCmquokRVFuBn6PQ+E4AtylquqONoIxFdgH9GiZU1EUO5CoquphRVHmANcDDcAu4Abgn0BUs4Y/pvlvLcc/BsxsHtvZfL6DiqJ8C2wAzgZ6A/8DblNVtanNeWc1r9WqKEqUqqqz2pnvKHAq8Iaqqq+0uS3dgXAgps3YSzgEPziE/rNt/jYV+A2wSVGUaFVVK4HJwD/aHHMbsAr4GHhSUZSFLRtCMx4BXlEU5XtVVXPoOFY1r30+cJcH85gIEpiavgmvQlGUccBAYFPz0FAcrpZJiqKci0Ngn6Oq6igcgu7T5uNeAzY2a8H34BCernNfikPIj1NVdRiQg0MQ3chxi6OxzfE3Ar/F4Z4YAWQD77aZcgAwERjRfNy5bc+nqupiHIL2380Cv735SlRVHeIi8FFV9RfgLWCroijbFUV5C7gEhwsH4DtggKIoXRVFGd48z87mezhFUZQIHJbMyubrCgVuBd7HYREkARe63K7vgNeBD5qP7yjsOCyJqxVFmerBPCaCBKbQN+EpohRF+an5v2zgaWCWqqoHmv/+i6qq5c3/vhjHhvBDs1b+LJCgKEpX4HyaBaiqqruB1YJznQ98pKpqSfNxf1RV9W9u1vZb4J/NmjLAAmCyoijhzZ+Xq6ra1Ly+3UDXdq61vfnWyb6oquqfgBTgMaAaeA74TlEUq6qqtTiE9AQcm8GK5q+tAKYA44Af29zHywAr8N/m7y4F7hOc9nEc7pm57VyXW6iqWojDYntHUZRkT+YyEXiY7h0TnqK62ZcvQ0Wbf1uBf6mq+hCAoighONw5JTg0SkubYxsEczU0H0fz9+OBeDfntrY9HoeSE9rmPNVt/uZ6/o7MV6H5Bq0WSjdVVf+JIyi8TFGUPwN5wCjgRxwungnAmRwX4F8AtwPFzf9uwe+BKGC3oijgcL+kKIoyVFXVbS0HqaraoCjKNUAmDtdTh6Gq6nJFUT4CFgH1nsxlIrAwNX0T/sTXwExFUVKaP/8Oh88YHK6O2wAURemNc2CzBf8DpiuKEtv8eS7wRxybgVVRFFeh/V/gJkVRops/3wOsbdaOO4KOzncMeFpRlCFtxvo3r3tP8+evcGj1fYDNAG188ZfTLPQVRTkFhxtqjKqqfZv/SwXWAve6nlhV1b3N6/y7kQuV4E84NunJXpjLRIBgCn0TfoOqqt8A84CViqL8AlwDTG8OQN4JDFEU5Vfg/4CfBN//EkfQ9ntFUbKAZBwBy0IgA9imKEq3Nl/5PxwbRUbzvKOBWR5cQofmU1V1DY7Yw3uKouxq/u5LwEVtXFV7gTDga5eA7FdAtKqqavPnO3Ckp+52Oc1fgWsVRekuOP+/cAR8PYKqqjU4gtgmH/sJDIvJp2/ChAkTJw9Mn74JEycRFEWZBLwo+fMaVVX/4M/1mPA/TE3fhAkTJk4iBLWmn5mZGQGMxeGzbWzncBMmTJgw4YAVR4rw5jFjxjglGgS10Mch8KW5zyZMmDBhwi3OAda3HQh2oV8IcMoppxAeHt7esRpkZ2czbNgwry8qEOgs19JZrgPMawlWdJZr8eQ66urq2LlzJzTL0LYIdqHfCBAeHk5ERESHJujo94IRneVaOst1gHktwYrOci1euA6NW9zM0zdhwoSJkwim0DdhwoSJkwim0DdhwoSJkwim0DdhwoSJkwjBHsg1YcKEiaDE3uKfyTqwhtKqQ8TbejC81yT6J54W6GW1C1PomzBhwoRB7C3+mbXqktbPJVUHWz8Hu+A33TsmTJgwYRBZB9YYGg8mnBSa/tKtOTyzKpvtRWUMSYrj4cnDmDGqX4fne+aZZ9i2bRvFxcXU1NTQq1cvEhISePnll9v97q+//sqqVau46y7vthtduXIlI0aMICkpyavzmjBhQovSqkPi8WrxeDCh0wv9pVtzmPX+8SrkrMLS1s8dFfwPP/wwAJ988gl79+7l/vvv1/3dwYMHM3jw4A6d1x0WLVrE3LlzTaFvwoQfEG/rQUnVQe14VI8ArMYYOr3Qf2ZVtnB83qptHmn7ImzatIn58+cTFhbG1VdfTWRkJIsXL279+4IFC9i1axdLly7lxRdfZMqUKYwePZqcnBy6devGK6+8gtVqbT3+m2++4a233iI0NJSoqCjefvttKisreeSRRygpKQHg0UcfpbCwkF9//ZWHHnqIDz74oEOUFSZM+APetroDheG9Jjn59NuOBzs6vdDfXlQmGS/1yflqa2v56KOPAPjHP/7Bm2++SVRUFH/5y19Yv369kyZ+4MAB3nvvPVJSUpgxYwZZWVmMHHm83eyKFSu44YYbuPjii3nxxRepqKhg4cKFnHnmmVxzzTXk5uYyZ84clixZwuDBg5k7d64p8E0ELXxhdQcKLcHarANrKK0+RHyUmb0TNBiSFEdWoVbAD0ly10+74+jX7/jD261bNx566CGio6PZu3evk0AHSEhIICXF0S42JSWF2lrnVqtz5sxh4cKFLFmyhNjYWEJCQti5cycbN27kq6++AqC8vNwn12HChLfhT6vbH+ifeNoJIeRd0emF/sOThzlpFy14aPJQn5wvJMSREHXs2DFefvllvv32WwBuvPFGXBvWWCyufbyd8e9//5u7776bbt26cccdd7By5Ur69+/PpZdeyiWXXMKRI0darQqLxaKZ34SJYIK/rW4TYnR6od+iQcxbtY3tRaUMSYrnoclDfa5ZxMTEMHr0aKZNm4bNZiM2NpZDhw6Rlpame44RI0Zw4403Eh8fT0NDAxMnTmTixIk88sgjfPjhh1RUVLRmAY0aNYoHH3yQd955h/h431gxJkx4An9b3SbECOp2iZmZmX2BnGHDhnWIYjQzM5MxY8Z4fV2BQGe5ls5yHWBei1G4+vRbsHj2eK8qYZ3ld/HkOmpra8nOzgboN2bMmNy2f/O7pq8oihV4C1BwcD3fqKrqHn+vw4QJE/5FoKxuE84IhHvnEgBVVc9WFGUi8AJwWQDWYcKECT9jxqh+ppDXCXujb9qC+52GQVXVz4Dbmj/2AYr8vQYTJkyYCFZU7/iVHRedj/2yC2n0QXZewHz6iqK8B0wDrlRV9RvRMS0+fX+uy4QJEyba4pvcMt7dfpicslr6xUVww5DuTOkb5/Xz2GtqsP/rn7D0fWhogHPPw/KXJ7GEeuSQ0fj0AxrIVRQlGdgEDFFVtdL172Yg9zg6y7V0lusA81qCFR29FlG1MOCX4HPpf79g35/upW5fLuFpveg9fwF7U3p2mkDutUCaqqpPA1VAE4LmvSZMmDDhL8iqhXvF24THe6ugrC4/j/0P/IGS/3yKJTSU5Pv+ROrDj2GNiYHMTI/nFyEQgdxPgH8qirIWCAPuU1W1xpcn9HazA09YNluQl5fHrl27mDSpY1wdNTU1LF++nKuuuqpD3zdhwsRxyKqFD5RWCcc9LSizNzRQ9MYr5P/tCZoqKogZdzZ9XnoN29BhHs2rB34X+s1unKv9dT5fNDvwhGWzBRs2bCAvL6/DQr+oqIhPPvnEFPomTHgBsmphGYYkxXeYPK5i0wZy77uL6qyfCe3ajd6vv0j32ddjCfFPXk2nr8h11+zAF7wZzz77LFu3bqWpqYmbb76ZKVOmsGjRIpYvX05ISAhjx47lnnvu4e2336auro5Ro0YxceJEAOx2Ow899BB5eXnU1NRw2223ceGFF7Jhwwb+/ve/ExcXR58+fXjiiSf4xz/+wc6dO3njjTe44447vH4dJkwEK3zB1CmrFu4dH83+Uk24kQkDehgmj2s4epS8v/yZ4nffBqD79TeR9sTfCeve3aO1G0WnF/r+bHawevVqioqKWLJkCTU1NVx11VWcddZZfPLJJzz55JMMGzaMDz74AKvVyi233EJeXl6rwAcHeVpmZiYfffQRdrudjRs30tTUxOOPP86cOXOYNGkSzz//PJ9//jm/+93vyM3NNQW+iZMKvmLqlHF0PT11FKAtKDNCHme32zmyeBEHHnmIhiOHiRoyjD4vvUqXs8Z3eL2eoNMLfX82O9i5cyfZ2dlce+21ADQ2NlJQUMC8efN45513yM/PZ/To0VJitLi4OObMmcOjjz5KZWUl06ZNo7i4mMOHD7NgwQLeeecdqqurTfpkEyctfMXU2V61sOvc133wvXAeV19/9fZt5N53JxU/rCckOpq0v80j6ff3EBIW1uG1eopOL/T92eygf//+jBs3jrlz59LY2Mhrr71GWloaL7zwAk8++STh4eFcf/31/Pzzz0JWzIMHD6KqKq+//jrV1dVMnDiRH374gaSkJO6//37Gjx/P//73v1aa5WDmTTJhwhfwJVOnkWrh9sjjGquqKJj3FEULXsDe0ED81Mvo/dyLRPTq7fE6PUWnb4zeP/E0JigzSbAlY7GEkGBLZoIy0yf+/AsuuIDQ0FCuueYarrjiCsLCwrDZbAwYMIArrriC6667juTkZIYPH46iKHz99detvPgAPXr0oLCwkGnTpnHTTTdx2223YbVaefjhh5k3bx4zZsxg6dKlDBw4kO7du1NVVcULL7zg9eswYSJYkRobZWjcV2jJ4XfFQ5OHUvrVCrJPH87B558lLLUngz78lEFLlwWFwIeTQNMH3zU7mD59utNni8XCo48+qjlu5syZzJw502ls+PDhfP31105jISEhPPXUU5rvn3vuucTExGgKNf7zn/90dOkmAozO0jYweOC+N4W3IXIHPTIsgdPm3c+uFZ87cu7/9CCpDz6CNTrar2trDyeF0DdhIpjQmdoG+hsF5dWScXE+vS/R4g5qqq+n6PWXKbjuCUqrquhy9jn0eek1ogYP8fua9KDTu3dMmAg2uAtGmnCPIUlizptANWI5tuF7to9PJ++RhwiJstHvzX+i/Hd10Ap8MIW+CRN+h9k2sONw50v3J+oPHybn97ey44Jzqd6WReINtzB863a6X3Ntu21QAw3TvWPChJ9htg3sOALdiMXe1MTh998j79GHaTh6hKhhI+i74DVizhjnl/N7A6bQN9FheJvT6GSBrBDI39rqiYpANWKp2pbNvvvupGLD94RER9Pr6edIuuNuT6mP/Y4Ta7Umgga+4DQ6WRBobdUf6EzZSY2VlRQ8/VeKXl2AvaGBhEun0evZF4hI6xXopXUIptA30SH4m9Oos6Eztw3sTNlJJSv+w/4H7qPuwH7C+/Slz/MLiL/w4kAvyyOYgVwTHYI/OY1M+BdLt+Ywcv5ywh94n5Hzl7N0q7HmdZ0hO6l2Xy67rr6c3TOmU3+wkJT7H2bY5l9OeIEPpqZvooPwJ6eRCd+hJS5TUl1E3pZ1VDQO5bqlx3/XjmjpgcpOanUpHSxlyJqCDrmUmurqKHrlRQqeeYqm6mq6nHMufV58lahTB/to1f6HKfRNdAj+5DQ6kRHMwW5RXAYOkt4zjYx853x4I4RmgchO8oZL6dj6teTedxc1O7YTmtiDPq/8g27/75qgT8E0CtO9Y6JD8Cen0YmKFqFaUnUQO02twe69xT8HemmAPC5zkVKsGTOipQcil94Tl1J9cTF7b7+JHReeR436K4k3387wLdvoPmNWpxP4YGr6JjyArziNvIVAZ5AEe7BbFpdJ6VKrGTOipQciOyn7oHhTyj5YIv2OvamJw++9w4G/zKGxpATbiJH0WfAaMWPP8NUygwKm0DfRKREMGSTBHuyWxWUKj0Voxoxq6f7OTgq1WKgXUI1bLWJnRlX2L+Te+3sqN20kJCaGXvOeJ+n2Oz3OuQ+0oqEHpnvHRKdEMGSQxNvEQe1gCXbL4i/9e4xnREoCoSEWRqQksHj2eLeCy9NsH2+gvkncW6K+qcnpc2NFBfv//ADbzh5L5aaNJEy7kuFbtpF8571eEfiz3l9PVmEpjU32VkUjEPfDHUxN30SnRCAySFy1vAfOHQpoNelgCXa3uJiyDqyhpKqIBFtSa6B51lh9cwSDRaUHdrudkv98xv4H/0B9fh4R/frT54WXibvgQq+doyNdvQJhGZhC30SnhL8zSETC77qlsGjGZGKs2yitPkR8VHBl78DxuExmZiZjRo9p/wsu8Fb7Qk+FX694GwdKtfTKveOjqc3NYd+f7qHs66+whIeT+tAjpNz/MCFR+hqv6F2bUUUjUBum6d4x0Snh7wySh1dsEY4v2ZLr+EeAO1t6wwUjmkMWQM0qLNF9Pm+4RZ6ZOlozFtrYwBtHN5J1+nDKvv6K2InnMXTjVno+9gQf7jioa31G1maU9jlQLki/avqKooQB7wB9gQjgKVVVzfZPJrwOf2eQiLTM9J5lXDk0j5LmPwWKn8gbGqVsjrAQcQDV3nyMnvN5w1po+3tvO1jCtOo87vn2n4Tv24u1RxK9X3+LrlfNwGKxGLofRtZmlEgvUEVs/nbvzAaOqKp6raIo3YCtQKcV+sFcmOMNBHumQqD5bUT57uA+ZdMbz4zr71JaXSc8zohQlQk/WQDVyPm8KfxiKkp4dPVb/HbnD9gtFnrcegc9H3+S0Pjj2rYRQW5kbUYVjUBRbPtb6H8EfNzmc4Ofz+83dHYWyhMlgOcviHzKqYJ8d5CnbHrjmRH9LjJsLyrVTV0gE35GIBPi3hB+SzP38NGjf2Pupo+JratiR/c+zDvnOiZP+C3fvb3OSTExIsiNrk2maIgUpEBRbFvsAtPM11AUpQsODf8tVVU/kB2XmZnZFwiufCed2FXzDTV27cMVaYljUOSUAKzIu7jmyz3sLtUKtYHxEXxw0YAArCiw+Ca3jEd/yHcam3vebnrFae+R7BnwxjNzyWc7KarSp0sl20I5KDj2qbN6MqWvs39a9nsn2UJ1n0/2bIjunWwdLce/u/0wOWW19IuL4K7oMrq/8TwDC3dTGRbJP9KvYNmQ82gKEYcsZWsWrc/o2kRwNwfgdC03DOmue16d6DdmzJjctgN+z95RFKUX8CnwujuB3xbDhg0jIkJbMNIeMjMzGTPGeEaCN5C9fplwvJZjHVpTIK9FhJylvwrHc8vr3K4z2K7DE7S9ljFjoF//HCfTvn+P8dTXrtJ8L/2Ui4SauzeemaIPtutef1h4OAiE34c5Vcy54jynsSdCugq10hemnwk4uzQmDOjBq+tVzbFPTB3LGIEWLLp3D00eSnpaucbVlZEXy6M/OK7RVlfNxV8uYWz2Sqx2OysHpLNg3AwORye4ve4IyXWL1idbmxFr9uY1y4XjH+ZU8dDkoUTlVEJ5HVFRUfTr3691DZ68K7W1tWRni91Y/g7kJgHfAHepqqp9GzoRZNWOtvBYPt/y0gnv5z8RWv75O+bgatov3ZrDq+tULlKKSelSS+GxCL5UE4mMjqV/ovb7vmYuHZGS4CS4rvvge+FxHfFXu97XcX0TDQlK13snc3V9uesUsIcyKedH/vDDEnpUlnAgtgcLzr2O9an63CIF5dUsnj1e9/o8jQ3J3EnbDpYKXaQbcov5bk+RR2yh7uBvTf/PQALwmKIojzWP/VZV1Wo/r8PnkLFQVtaWUtn87xPZzx/sLf+CIebwzKpssgrjdDNWeoO5tJstnCNV2sBtN1sEW++fKlif5/5qT48VQcZblN70E+O/Wse4A1nUhYTy9pjLWDTyYhrDwkGnq3pIUrxfg/wyBSnMaqGxQbvmtlaSL55bvwp9VVXvBe715zkDhbbVji2FOXUN1VTWaXf9YCHgMoJgb/nnraIhT2A0K0X0zBi1BG3hoUKhn55WprEwg3njduUtstQ10P2jzQz+9yZC6hrYlDaU+eNncyAuGYARyY7nryVlc2hygtTN5K3r05tpJbvPtY1NmjEZvPncmhW5PoQrC+V76/8sPC5YCLiMItApke5gVOCKXuCMvFiP3EMdcYF5ylyaV1ZFes8yLlKKSe1SS8GxCNTiaM4feFRTLzBBmdnq5mgRlO42bl+6y1znvu/MKGi2iaN/2k/KKyuJyC+hvmsMfxk1m/8NSIc2tMct654xqp+TL9yom0kvjGRayRQkmaUlgjdz902h70ecLN2mgqE+wYjAlb3ACzPSyCp0uGY6YmYHQpM+q1c5N43Ja/3cK65WmEEEDotixuj7NIJSBF+6y0RzH6mqo0dtJclvfkv8ml+xh1g4cukoKm69mBvjr+eQAUFux469+f8dgeh5NkqbLVOQRM+HCN6MlZlC3484GbpN+bI+wchmYkTgumsmIvLHA7py2wPhApsyUL/VWFp9SHeevi/dZa5zhzQ10X/VZlLeXYe1spbqQUkU3HMBNYOSsVjqiEAsyF2v5dwBSR77x909zyKUSOi0RZgxqh8bcot5e+NuahoaiQy1MmFAD75RCzXHelNRMIW+H+ENn22ww1eNQ9y9fO7cMHoErpFmItkHSwxpvEaKdYwKT9EcojVLYYnXfS2+pAxoO7dSnMuD6xaRVpxDY3QEBXdOpuSi08Aa4nbNG3KLNQJe5joxslHJnuf6RgthVq3lcLBCf2r50q05TmuuaWjkG7WQKUoKa/cUUdPQRGRoCLecOeiEzt456RHs3aY8ha8ah8hevnW7vuamZSnHj3MRXHpeFiPNRMKtVkYkHXXymX+pJhoSJL7kwpl7XoTUneOKL9TuwnHRtfgyRXdIUhx7cwu4/cdPuWLbKqx2Oz+OGEOXh9Np6Bqta81vb9yt+3zbi0p1W42y5znEInYVfb69Gw/rZGuWWU9tNf2ahiZeXa8yrm+iGcg1EZzwVdxC9vI1NJQAKZpxI0JY5nb7UtUm05+WfJTbxjr7zG9Pz+OtH3WdCmifXVGPBSCbY9fhaKHQ33U4lvTeNicL87bPsxDRf4q0d6PxCb2WjN1u50n2Efrh43SvKmNfXDLPjb+WH9OGsCglmQQXWmrZmmsaGoXrmDm8kAn9SggLsVPfZGFtTgL19kSh1bgh9xDPfVfjtGbZ89yy2bvWYLi6A93BCLWFmb1jImjhrbiFq9C4/fQYokLLNccVHAsXft+I20HmdouMjtW4hw4c+pdwjssHHxWOizRKd3TEnrpbBnWvFI53iaznstH3OY0NSdqvW3s34i7Ta8nU7N7Fvj/dQ/KqlTSFh/P5pJm8NOg8BqUmsrh17gt0rTky1KoR/DOHF3L+wOO/S7jVzvkDj9LQdEzzfYC9h9aTVTjQac2LZogb4WzK60lGfpRGyPeOtwnnFkFmPYmwTfLMdASm0DfhVXgjbiESGou2xHJ7ulbor9ydJJzDqNtB5Hbrn6gVtu+uF9cRJkbXaMZkcYizevXi+/2xutdmxN0iI3lLtGnXbVR71+suk/UWmLNiCzNG9aOppobCF56l8Pl52GtribvgN/xy8wOs2HGMuqIyt1k2sjXfcuZATU7+hH7ipuhWS71wXBQPmf9dLcuunylUCL7aqV3H0wJefxlk1yJCmNV7rU9Moe8FBEOKYjDB07iFyHWRkR8HGWjM6R8Lugjn8FVaZIItSWjuJwj64a7b+bVwjgsGHhIKfZmoE1kt5w5IEgr9Q5WRpHTRbkBHq7UaqCsHfXt5+jK4Pv8p0aEcKNW6OfaXVlG25n/s+8Pd1O7eRVhKKr3nvcA3fUcza/FxSgh3Fk57FsfbG3e1BkDDQoylaIpiONuLSumfOFWoELhbhx6IriWrsET4HNQ1it1XHYEp9D1EZ6dQDgRkrouMfC2lwYiUhNZKTG+nRYr80ukG3FeNTUcJsWiG6SnRxiNDQ6hp0FZpiqyW7/YUCef4fn8qVw7dqxlP7TpOeLyooMkIRM//7elABk6/VbfKUu7dsJSdCzdBSAhJd95Dz0fmYo2N5Zn5yzUFZe6C4yKLQ5sJ00R9k4VwQYZNox1CBb+LKIbjzmL0VnFi2/TTNEnbx2HJ7knkjMAU+h7CVymKJzOM+DrbVmJ6EzK/9OLZ45mgzBQ2E3dFg0ToNNgFEge45cxBZORkaITfvZPGa46V+XhLBBQMAOP6el4AKNoEo+zuaxxCmpqYvn01v9v8CTF11USPTafPS68Rfdqo1mOjQ/dx6+mC4PhmGDl/ua60VpFLaW1OgpNPvwXf7u3KXy/+jZPLpqJxKBn5WgvOWxaj6N4BmmcMEG6AomegozCFvofwVYriyQyZr/Ou8Qpr9xzySaGTkW5TW++fKmwm7jrHPWeI3QuhIXYhy2N6WjlrE7XCLz1NG8sIt4qtgt+eclh4znW7vvZICZFtgm9fXtSWDaEVKV1qObU4h4fWLmLw4VzKw20U3/9X9lzy/7hm5Xa2v7+tVfhdeuoR4TkvPKWYuav1VUSLtOMlWY6sLtfsnSVZKbx/g9YFaQ31jEJZBtm962bTJiGk9yzj9nR9z0BHYQp9D+FraoUWf2lJdRF5W9adFPECo5WsnhY6Ge0KdZePAAAgAElEQVQ2pXeOkuowutm0QcP6pihAW1UqiwF8ve1LFv643+n6ZGRdIn8+tKS26sPizSspOLqBrlFVHK22kdp1HM99J563pDqUri7XGFJRQ493NvDOl1sIwc6GERNJeeoZGhO6CYXfm5eJg+OiwKrR1MUlWSmtwr89+IpLShbYFhHjdaTFplGYQt9D+JJa4WSOF+h9Ab1R6CR7KUUYkhQvpC4QzRFmFQffGhrrhGt+67KjiJo9hYWUaZqMi9ozgiN/XJSnL0ttdcXizSupr11FYnNNVGJ0FfW1q4iypgHa4GxT27Cj3U7ctztIenMNYSVVRJ5yKn1efIWx5zrehZHzxc1EZGuWBVY9RTeb8YZMnuBAqZYET5bTb7TFZkfgvTygkxT9E09jgjKTBFsyFksICbZkJigzvSKUZZrful3i8ZMR7RU66YFIeMowYUAPZr2/nqzCUhrtx4WwaI4u4WJt3BYm3gzyBUIOxMKvqk48hygY2TI+cv5ywh94n5Hzl7N0q7gLacHRDcLxiyVuo4RIRweq8Lyj9JnzEWnzvsBaWUfh9edww9V/pfuK/NbzyQL07tbsitTYKOGxvQzkx788fazuY72BFpdNr7harCFtXDY9tfejQPIMeJOU0dT0vQBfUSvIsj+MmOqdHb7khAFttynZJuMNfKkmOvlz24674kiVWCPcXtyVhYLUVodW6WwtgNYa6hol3gCTJW6jwyWhDPvyO7p/mEFIfSPHxvaj8PeT2WtL4qfVlU7nk1knsnRckSZcWdcodOc9M3W0MA7k4LE51EpodsuZA5kxqp9fu6pdPkQcsxAR+smeAW+SMppCP4hRUB5BmtBU9695GiwQvaje4ISRCaPe8dGablOyFoPewMHKVDcCWwuRyyCzIF6Y2iqCyD9+tNpGYrT2XoisjTMOZDH87kUkHj1MffcY8n53HsfOHgQWC+ruaOaet9tpbQcrozVzgKPbl941H6mqlWZVufYGcG2iUtPQ2PrZ192p2iIpRrxhpsVqffoZ+XHcFaEQY93WbnZYR2EK/SDGL4f6kBa3UzOefahPAFYTWMh893eNV4RC30iqnUxLfHrqKM2YkXTSI9WhdLdpG3BbQsTC79Jhaby6vlKX8JNleSzMcHx23QxEY1sKtWZkatdxwmbum/J6tm4yveuOkPD6d6Rs+JVGSwiRN8+i8KrBVFjKSYjqwUdZdU6pki1re3MzXDos3amA6pYzBzGub6LuylQZWrKq2tYcyGIIMnI2b/DbiAo1ZQV9XaOT3PTqvUCTHeYtmEI/iDF95CQWrKnSaH73TpoY6KW5hS8qlGVulbV7Dhlqci2CLFsItHniRkrnl2UnC031Cadcyl3jazXCT1ZwJYIsy+PKYUVOGUMtArctWsY+3hauyQ4b13cSG3Ina7J3Zo6G+qqVdF2+lR6LvsdaVUfV4FQO/fERGk+d4mSBXTlYzD530SmHeXy1cwFVC4Ok62+YX1YpzG6RYXtRqSbALuM4kpGzGXUJuj7nSXH92VH4Q+vfWxIvTk05Syj0He+F/7vPWew6mwkHApmZmX2BnGHDhhERYdyl0dEqw2DC0q05HpfJ+xOuGUctCIuY7GAwPFjKkOT4Vh+qXt9q+APv09ikfVZDQyzUPjfb69fhalm0YPFsR5GM62/y8IotQhdRi3bcdtNO75cu7N1qQU7F4Io3L9uGiI7FbkeYNy9CZV0o0eFaS0SUiPDl+38k5rmlRO05RENMJIdunkDJb4ZjCe3mRG3tbm0NTXD751oLrKWquu1z4NoApQXuXHH7S8Vkc64QkbO1rMPVnSeD7DkXIcGW3NptywgflSfyq7a2luzsbIB+Y8aMyW37N1PTD3J4Wibvb8gqlEUMhqLGFzLfqjvfvRHLQrbJuM7xyc+xQJjm+/NWbeOhyUNbc+tb/i9zEYl81VsLtS67FuhN7TtWF0N8ZIV0Hj2whWkFPjjXBZwea+WvO76k+3+WYLFDyQVDKbr5XBqbs2VE1NZGUjDBUV3s6rrLKixleEo82YWl2HFsiBcoKVw/doDwPlfWiUnURPBGdyrZcy5CafWhoOqjYQp9E16FkS5URnyrMrfK/edG6K5lWLo1hwVrvuCKwcXcne4QqgvW7KOxQXHyY5dUHeSiQQc5UJKmEbhZhSXCOdL7pesW2PVNduGxgNBPTwb8UpTg5ArKKTnCqBSt0K+oC6FLhDhVVC/CQsrIKijhwl0buGfjv4mrLqemdw8K755E1fBeTseK8v+NZCEBNEm8DW03eTsIBXULjLiCdhSVG3IJihSFmir9rrhg64FtCn0TXoWRLlRGfKsyv3uU/XNECaxZB9Zo2iimdSkUCtUj5YeIFSihopS6sZIA6uo9Vdyerg1euhKPgTwIe6RKa1m4rqPFD/7EeeK03bpGK6BP6DfZwSpwBdXuLuPVFc9yesEOakLDeS39So5ecS7Th+/THCsS5EZSMEG/SwtgpRvBrxf7Sys9Lv576vwIafWzKyoafcP42lGYQj/IcaLRMBjpQiXzrcrSLUUv6nvrxZZFSdUhbv7U+WW9YnC+8Ngu4WItUWSdXDlMrOFN6CduoiLaOGRB2K5R+nneZb1w4yLrWZiR5iRw1eJoIfFYXWMoUSHHXTyW2noSl2yi28cZhDQ0sb73aTw/fjaFXbrDXnjpai2v/M2f/iJch94UTKNwt0GIumTppWAAsUYvSyD4z6/dhdbM/3Z3RUmsdNrsappqmeXfejC3CIjQVxTlDGCeqqoTA3H+EwW+pGHwVXFKRl6sRujItDxR4wtw+FZFfnpRA3SZZVFcGakZk5W4yyCyTmSCWaQxy84po1aWobRG+5oWHhPXcBRVRAoFbmltPLeOrXIS2GvVpa1/j8nYS8rrqwg/WEZdYhceHXUDa/uOcooKZ+TF8szqAWwv6t58/2MJC7FQLwiw+xuzRhRy3gBtlyxAI/h7x9s0z79r4LhFoxcVR4IxayY0xHtdr7wBvwt9RVEeBK4F9IXaT2L4irbZG3w1MjyzKpusQq3Q6R0fTXxUuCYLaVzfRDHbpGCzW5iRRlahM+viu1d1Q9TO7peDWqEvCzCW1YYRH6kV5jIftBE0CmiUG+wWwg04NSxo5/jvrkRuOV2raW44kCqcY3b6BVzm8ttm5nxJbX4eyQtXE7d+F3ZrCIevHMuv085h7drhmjlkz4wRiGIZ8TGnkp5WRjhZJMfUcLAikhU7uhuyFMb3Fbu7JvQr0Qj9U5PihIFjEawWizDmYLVYdFsz3mge700EQtPfA0wHxM1GBWhOPeoQMjMzO/zdQKOkWuxKKKkq8ui6Hv9yj3h8xWYGNYndFHqxXZIbnV9WyccX9aE106PpKJmZRxkEvD0pxWk8Y+c3wjlErpLC0j30iNEeOyxJy9woCzB+lJVEk12f1na0OpRugoIrGawWUZqpMc1YtCFtOBBHY5N2zZvzxdw0OXtzyGzz29obGrAtXUuv97/FWl1P5ZCeFN59PrX9ErFLYguyQLXeAPZZvcq4WcCbX1FpISb6QOt4z9gabk/PY8DuKpTEynbnBaRdskTj3+7SKgkyyKyY8BCo1tnM6up+tg6/r76QX34X+qqqLlMUpa+R7/gyT98bbg5ftUvM27JO0povyaNKvZylvwrHc8vrPE4LHbKmQKg1DU1OYMyYMbp+k6z1HwvHRX7sbjZxMC0pRnts2xL3tm6OuWt2c6C0SpfW9rGk4OqohEZZRJmRXy62OFpSE10hshZarkevNvzm9hL+nVPJ9qIyptYV8sdv36PHnh00dIkk/w/nUXrBMFp8GXGCTUYWfB6wu0pYfSsKYP9mkDiWERmlvZ+A7nkBaZes+ibtvavzgjuqutHOXeMV3t64u5XXR5YK2q9/P8Z0wIL2Up6+Bid1INeom0PYPk/iigDP/e6+om32Bl+NDEabbYu424sro3Tzv5RU2+guODbB1sNtibszduvWVmW+XEB3mqLM4pBJfZG1YBT7S6uIPXiIBzZ9zOU7vgPg8PmjOHzrOBrjnBkqRfdZFnyWNR8XWWWpseJYhpHrE80LkJHXjfF9tEyga3O0bQZlCQRG4crrI0spdUfv4E/itxZ0SqEv4jsX3Uh3tLyiHpyiDeKd6eIf2htND1q+r6c1nzuIglae8tWI5m17n0V++s+3vOSUhbQh95CQu/2Xg12ZPEAryEUC9FjjULqzWTMuK3EXrblnl0Jhuz6RVunWl6szsCfbOC5SiiVc+B4S7NntXLTze+7e+G8SairYk9CTZ8+5jpgzUrgpbr/m8LW5Ka2CsYWZMrWLmKpa5lYRWWXlteKCMpmWrndegEVbk6mpb9KVvSNLIBB1Zrvhg+89DlQbabzjS+K3FnQ6oW/kRhqh5ZVtEDL6Y281PWip5Oso+ZLofmQVlnrcerC9+9x2LlkWUnltuDA/XulepTsDKPPAUfpJ9qp7P81w4reZMCDJSRtrWfPfL9BPfdvohrbEiLtFdGxMRCizTsvVHOtJQLlvST4PrvsXowtVqkPDefWMq1gyfAqN1lDYD/WN2vucWRBD3fxrnOZ58osvhBuSTGCLrIWPs+O55XSt0Jf1shVBVtXbaLdLu2S1NJxvKWxbMC0dwMk1c8uZA1vH22L2Ys+I4EBuQRtROr2JgAh9VVVzgTN9MbeRG2nEzSHbIGT0x8FSheeOqEwvz4iReUX3WZaFJMuPT+5So1uAnpEm9gd/ve1LXl2f1vq5pqFJan4n2sTt+lK71LXy4bTQALirCtWLmPBQKuq0weBdRxNZmNGgu6jJHSLqa7lpy3+45pevCWtq5Lu+o3jxrGs42KW78Pi2ekuIgLxH5pKSCWzRRiULPrdcX1stXS22MTxZm+CXdaiPoYAyuLKLlnDvp1rXTAvxm+uzOyw5XigjjLiIZBa0r3tByNDpNH0jN9KI/zk1NkpI9LQxL40r47TZMN5seuAJjD5YeoPSRuaVUTPIUFJt0/jjfykU+45luffhIWVAmvBvriiQ5LyX1oTyuBMnfBkW4gxVkIpQXd8ojDfMXryeA6WeFzWdve8n7l//PikVRyiM6cbzZ89mfd+RmuPc0TNHP7TYSTt2l5e+56hN90Yl2szPTCtz2jjCrXaGJ1cKC52Gp4Zz0aDj3EUtaz5lTxWTBggCv23QMvZOZgjQRbM2kcIic4XKgrZGLGhfxtbcodMJfSM30mgDbhG2HerKy9PTDTPo+QtG7oeRYjAj88oKqCwh0WDXanOpXcdpXER9n1wm3HRlRUpG/OBfSLTYbrZ6ujX/u73sESNotNuF1cU3L/2BmgYthYLeIHPSsSP84YcPmJi7hYYQK4tGXsQ7oy+lJkx8L2TVxVcOK9LQPkD77qv2yD2tFovQPXbhKeIgsZJYydzVA53Gpp4q5ms6W5KnL8IFA4v4fr9W6IsUFhnd9cHyGo8pvY0mPXgLnU7ou9uZRdDLwVFQLnYBFJRXBxWDniuMPFhGisGMzCvLQppwyqVsyD2kyd6ZNfYCjcXxtwuHct1SQXB3ZyK3jdVP7iVCRn4ci5VznDbuXYcPCxugyLJHvIFaicCXkbC1rMPa2MD/y17JrT9+RlRDHVuTT+HZc64jp2tPt+eTVRfLxkVwl8rpmmP/Y4H4vskqlEVWXLKkC5UsoKx3XjDm1t1eVEp6Wjlzz9t93CpO6yU8FowlPZjZOwYh25nX7jHmYnD9kWTunUBU2xmpCzDyYJVImANLDLpnXOEuC6l/IrimUIosDjjIohmTmf9draZnrajF4PbD3QB9RVSRoVYNxcDd6eICnpQutbo1b6OIaA44toUsVbJl8xlxcBcPrnuPgUfzKYmMYf74aymeNIzrTz1MapdtXl2fbB0iiHLsu20L56ud2uKxJkBAvy90o8ksu4YmC2E6M4DqmsT3QqSwyCzay4fUG2J31Zv04A90OqHvjeCI6EeSwdemmCs6wsej98GS5ccfrIjQdpBasUU4x5wVW4XnMpKFJLM4Yqzb2Hr/fZrxWe+XaoRar/hwKmr1Cf3EmAjN7y2lbKgJa1fzbgvZBuGaWXTLmYOEmr5MK02zl/Li5oWM27IRgAPnjeS19KuoskXrXp+sneORarFYEF2LET6js3oX8tXO/ppxGW+RaFzmiiup7UcP215d64iNPh0RdYcIMs/BxH7igP66XV8z/b39ukjbfJ2lI4Nogz2hMSRJvIsb0chlP1Lv+GhGpCQQGmJhREoCi2eP9/uP5s4F4yk++7WrcPzz7d3IKiylscneqqWIrB5w0NYu3ZrDyPnLCX/gfUbOX87SrTmG1mHE4pgxqh+LZ4/X/C4yd5wIomuRuYfskjCuSONtcX30iqvFGnJcAKf3LOPV9WqrVt/iNxel/mpiE0124r/JQrn1HcZt2UhN3+7sfX4m5Q+ez7UTS6R+etH6lmUnC4/9qSCWueft5s3LtjH3PEfhmuxaSmvElA0i9IiuFv5WRnCwMpWwiMkUV9pobILiShthEZN5cMptwvEJykwSbMlYLCEk2JKZoMzkkf+WC+eeI1BkPs8+IDgSIkLEc9Q3HNW8K9sk1CS+ztKRodNp+t4IjsjTM6vIeWx6h9fmDcgyYbxRF1DZ0EfoKjHqGvC04MSIxdFixbjO7SB+6/hLJctWuVUQPwCxRt6ea8YVjYL9pG2qZETuYVJeWUn0tnwaI8M4eOu5HLlsNIRaW483Qs8sukZXGub2uP5lm6AIhccieGyC9rea/40Ri8POrLEXoK2qpnU8MzOTMRMc1qSj4rucrlFN7Cwup6LxkBuFRTsuOzbfQHcwGWlbaqxNM+YPSIW+oihNOLvV6oFGIBIoV1VVW98cBGjrw+5oX1mZHy81NkoodGQQBW8Aj8quZZkw8VE9pMEivaXejg1T6yoxAhnVrhFT9rNfu3Lr6dqXrcXigPY3EyMNzGUQZavcOCZfWIwk4seRuT5kVaWyNYSvr+X3v3xGvy82YWls4qchI4h6+EwaesTqnkdW1OR6jXPPE2fHyDaThMgGJijOPPvLf20QUyLkpgifxa93pQmL0kSWiDsLzrUS/7IhdfSL3ayp+E7vqe2IZhRGuoPJK3oDQ0ktFfqqqoYAKIryBvA9sFhVVbuiKFcAF/ppfR2Cp31lZQJjf2kVNO/8enh62qOi7YgWLMuEqWgcynVLtecz0odWFPQtqa411Ii6QVKxasSU7RmnXwOSbSaia5Hl+htBqIQnRsQfY7RXLGj95gc+O8jUxZ+RUnGEgi7dmX/2bH7ocxpvJ25rN0WyLUTCKCbcSkWdc4GR0Z4DJTWhmuy1e79YxraiSI2VtKekq/Cd6GZLoKJWX1HakKR4qTLlOve1I8S9iNumpLYHmRKztTCBCS4ZX8+tDTW0mRhxQXoTetw7Z6iqekfLh2aWzEd9uKaAw4jwkwkdWVxABCNacNtMmLZ1AdPf03KogLE+tKAN+rpuXi14euqo1nlcs2mMFJyIXuCLTzmMaO8QuUXcbSaiXP+U6EJNMHJPSQ+OVOkTdnKzXsvfb7RXbNv0x7CiMs56fTWxm/bQYLXy7qip/HPUVGqbc+5lrJ5Hq8P4ODtJlwCNCA3VCH3ZRtVoh1DBLiPi+j9QWiUpMhPf4yNVdRyp0h4vChyn91OEG0eveK2iYDQl9dbTi/nX94/SaG/AagllUHK6lHajyW7XbHbTF+tmiwcCx7OvR+hXKopyI/AhjsDvtYBnpOsnAFwFRvgD7wuPkwkdWVxABFmgRwZRByPZ+Yz0oRXBXcrn3uKfNXnKRmIqMmvorctLhEFNkVvE3Yvjmtr6+zNs9LBpM1sW/xzK6r3Rbu9DC2SC/AtVS29gtFfsRUoxNDTS/ZMfSVy8gZDaBiqHp7Hlhov5x05n1pKPs5OE6/g4O0k3hYVoo5Ndn6yDVHxkvSYTyRuQ5f9/vC0c0KZ9ynzvejFzeCFn9jraGldptDewo/AHfn9GMq9u7KY5fmiy5wLb35l/LdAj9GcDrwIv40ip/R8OwX9SwWjJtOx4EcKs+l8UmaDsFW8TPvhG+9DK6KNdhbssdXSCMlN3paLMGiooDxfmYovcIrKiO9H6eki8RhP6FrJ670DxH11gVJAbIWEbtH8PPV9dSeS+IzTERVFw9wWUTR5CnN0CLp6KX4q6eiXorvf63MUyMnIyeHiCZ3ULrlq9LUzc3P2MtHy+2qnvt3KXkur6jJ4/cIdwjlEpxYBW6IsEdliIhVEppRrrZGthAu9ec5bfi7BkaFfoq6q6D7hEUZSuqqp2eg1fBqNZQUYCiXWN+rm9ZYJSZGaD+z60rhBtKAvWfOGkcbUI9+hw8UuddWAN6b0m6apUlFknslxskVtEVnRnJIXVSGC1my289d9t77iMRE0P4qqPcdemDxmw0HHvj150GoduHE9jF4dGa7c7AqyuLQa/URsN1QbohWijulXQmhEcMQ4jdQsiiLR6GYz8VsskDW8+257C+vucLfl318veVTFPkihBYlRKqfBevLlZXisTlHz6iqKMBJYCNkVRzgTWAlerqiquzumkMFoybSQuMCxZfyKUu3RS2cMp6kOrV/OWpR1W1onXUVJV5DF/z2YD2rTMTWWE5O1wlbjFoIg86/9++JpZp4lfbLvdldHRvbC12Ju4ZMc67tz0EXG1lVT3T6Tw7guoHuzc5zY05LggbOuSAq1Lyh1tQ01TX6drMZLdJItlyPr9GqGrkD1jIhwSNLwHx2b88vR0p6y9+JgUoTWU3m+s7vOBWGCLFKS554mvY9oQsa4czHz6LwPTgA9UVS1QFOUO4B+Alny6k8NoybTeoKgR3547N5NsfXrXLdpQZNkcdjsIGHhxhH20lsu6XV/r5u9xUBjr0xRlbipZaqsIPeP7CzfMDbnF7Cwuo6HJzs7iMjbkFnPhoHzhHDNHFNIl4vh1t6fxDjxygAfXLWJE0W4qwyJ5cdxMRv+xF927iN0arpC5pGQCdPrQozzwm7ucxh5esUW3L1zm65dlMxnJAjJy7Jq94oKy6PBQTdae430r1Nz/eyd53vBepCDJriMxWswXFKhKXT3OZJuqqq1NVVVVXQl42Mrn5ISsetQoM58ID00e6nElrKiaWcZWebRaXKzTZBe7qhoatOmSM0b1467xSmvwLzI0hLvGK3x12/nN49bmcStTFG1zDJBvmEaorWPDHU1U7M2lRnbsvLd5j7BqVpb5ERMuvm5XIRxVX8PdG5by7rK5jCjazar+pzPj//2df4+YgsVqFc4hgszNIRM83QU9Ay4bJicIc0VGfhwLM9I4UBZBQxMcKItgYUYaDZL+vbK+viLInrHDVaGa88kC7qL0x2dWZZPes0xTXTxvlbYLmNUi1n9l4yIFSXYdCTZx3CmY+fSPKopyGs2VBIqizCLIs3f0tksMBDwlWJoxqh8bcos1XX/A80pYEc+ITMPLyO/P01NHa1JHP8j4RDfV8dKtOS7NLJpam1ksmJau6WS0dGuObvdaRl6spvtWz9haYRZKSdUhbv5U211M1pTDCFqFsN3Oublb+OP3i0mqLCEvNpH5Z1/Lxt7DW4+NFzQkl6FMQn8gS7nML9fefxnFgAxCX7+kQllkAcSEWxmSeFRzT2XP2E8FsSiJlbrqEUQWX3ToPmEbzLd+1PrS/3BWMti1a0iK03IFOc6ntbhl1yFTQIKZT/8O4D1gqKIopcAuYJZPV+UBAuUn8xe0gtLR9Uf2As9btY30tHJdrJwihlJZNse9kybSP7GfZp5fDmWSFqctisk+1Ecz1hHztq027g6OegFttalIIBYL/MQy3/ixWquTG6c9NNotpJQX86fvFzN+/880hISSddkN3NV9HLWh4U7HHqsT95AVQXb97lJKP/7VuZrc0zRHcLBbirJ6RBbAkMSjkqYtaZoNWkYHESNJrxVZfJcPFuuml5x6RCMj9pcU00vgTayuE3PsiFyTGflx3BWhEGPdpqu3RjDz6Z+vqup4RVGiAauqquK7ECSQsz9u6RRCXyYoZS+wLTSXterxB8tdYFVmbv5YEKcJAsru5fSRk1iwpkq4SbjCnXkrauaut7JYNrdMIIqI5mS+8dpGi6Dn0vGWim1hqW8k+eMfWfLRJiIb6vgx9VSeG38dl1wykVpBRlVi3BnU164SntcV8ZHiTCH3KaVaCgtPESrhsRdVKLvjIpq7eqAuOohJ/Yu4+azrdFl8idHiitdEm9bHLnOLyTit3Cd2aHmBjM/hO+gR+ncDC1VV1dbcByGMkCmdiDBS9AUwTaLtiBqjyMzNYckJuvvpOh7Yi3U9yPGRYRyp0vbJjQy1Cpu5i9Din3VNexNdS0Z+HL13RXPNaWVOmthLG/fTIhBbIBMCXSXCtrLO2QKw/XKAlFdXErn/KEejYnnmnOv576BxYLHwxvdieoD539Wy7HpnHps9h4/QVVB5647KwUhtgF609Ap2RX652J0kcucZ4SKSHdsjulq3izTBliQM5ovWJnOLuet17Q0u/GDl0z+gKMpqYBPQunWqqvpXn62qk8BIsxO9kAnm3vE24cbWXaLtiDQYb5mbeh/k8hqxD9tIvnv2wRKhO++u8YrwPk0bOZHLXNb28ORYzXXLhIDMwRwV5hD41tJKkt/+jvj/bcdugXXp4/nrkBkcizjukpCV9m8vKqV/4lSnZ2TcC68aonKQCWdPIZtTLY4W3ie1WOuCccdF5Jo95e5YvbntMp6qrEO9NWNG/fEnMvQI/Y1t/m2E4ykgkFWm9o7XV2bvLXSk2YkeyJo6nJoUJxT6FksCdrtW2xdpMP42N+Xsg/oRbhVXHK/dc8ijHqYyISB7Aax2O1mv7Wf66uWEV9ZQ1i+Zt6Zcw8cMl3xDCxGZWIxB8nNf8TbKKrtPTzsmPH5kajlLspwzrmT39KudiTx2sbOicPaLucIg8ZdqIhmr9cXsZDxVkdGxHCj5QhNQDouYrNsfL0Mgiq2MQk9F7hOKovQAxuPoP3wlStMAACAASURBVLdOVVXP6Qp9hGemjnZLEOYvGOk36w6umUil1Vp3CMgrU7/cmchvB2mFvkyD8ae5GSloDwjGtFVZNXNL2puewK8oDmSEjiByzyGSX1nJsB2FVIZF8srZs1g25DyaDPYomjCgh+6CH1/26hVBVtktyzjqFqW11mT3tKapr+ZYo/qALGYn7l/9szCgPK7vOfRP1OePF6E9Zt1g2Qz0VOTOAp4H1gNW4A1FUW5VVfXLjpxQUZQQ4HXgNBy0e7eoqiqO2nQA3uDT9wa80ezESNtGGbHaZ9vDeHrqTI2248tG7o7GFdpm56645cxBQkHiKM7StqOboqSwds8hp1TVz7MPCC27uMhw3VlcsjiQyDc+oGtVa1ZJSFUdif/6nm6fb8HSZGflgHQWjJvB4ejjFdaitM/N+XHcOV7RtEsUZU95g5PfHfRSNozrmyis7K6p1Oa8y9DNFi68p4tna92HRhvQGInZeUshc4UsyWLOiq1ONOSBzijUYzw+BoxRVTUfQFGUPsByoENCH7gciFRVdVwzrcPzwGUdnEsIT/n0jUJk0rlrdqIXRuiZ3RGribUd32Dx5pXU167SNK5YvBmN4G/Jw3etOVgwLV2Tkz9hQA9hqmpbLpy2KK8RW0RzVmwVcrHrxZKsFLDbubRgE2lvribsSAWlid34y9gbyOjlPJcs7bPbtnBhfYKohqC0RkyhXFYTZohjR3RsiMU5z95dFfGcFVvIeewKjZB6eVU4sRHaey0q3osOD2ulSmiPx+budN9tdr7qPidLshD1nYDA9ci12CVBpRYoirIZB6d+U5uxH1VVPb0jJ1QU5QUgQ1XVpc2f81VV7Sk6NjMzsy9grKzUz/gmt4xHf9CW5s+fFEJCfJZmvKR0OP/YGkZOWS394iK4YUh3pvSN45vcMt7dfthp/PEN+cIWeiJcfUoCH+7Uet2eOqsnU/pqBYHofKLjjGJV8XJ6xGhT4ooqojg/UV8GkAjXfLmH3aXe0W5dERceQlmdPvqD1PJDPPnjuwzd9StNoVb2Xn4Wrw++lB8OaamVZXUBeWURPL5aS6EQaoHRqc7COT6yQVgXIKsXWJih7Qrluvm04EiVeEM5UBbBXMH6Mq4Zohm7Z+0Goe9dtA4L8PXVMRQ37KDGXk6kJZbE0FPJyIvTvEOye1dQHsljqwZoxpNsoSy//BTNuAi7ar6hxq4V0JGWOAZFTtE1hwhGn1GrBTbM1N5TL6PfmDFjctsO6NH0NwNfKoryTxw+/auBQkVRrgNQVXWRwUXEAm3veKOiKKGqqkpTNoYNG0ZEhHHmB39o+jevWS4cX7QjTpN+V9E4lPvXHKSlmcTu0loe/SGfgyExvNrmoW8ZlwelbcRHRWi0pct0Vqwu3ZrDoz9s15yvX3/P/fk/rf1ION7NVs2YMWM6/JvkLP21/YPaQGb5iBAaGgZ17l/WsMZ6Zv38X27eupywhnoqRvWh8M7J1KV15WaKiNsWQ2pcFL277Gr1V6fGiudMlmiro1P1s03KaB+uGq7tCiVzlRjppwsIf7f8L3N1Uzyf1fsYB+qPu4Nq7GUcqN/E1vJTAGfLQBb07ZN4NqC1oF+YfiZjmp/d9p6xhOJQYVZPY/jp3LymoMN+9ydCugrjibL3eGhygtt1eiK/amtryc4Wewr0CP0ooJDjLRKrmv+bhCPeZlTol4NTfUuIO4Ef7HBXYOSafjdyvniDeHvjLuG4jC756amjPSJW8yXR08GKSHrGajX9g8ciHf2FdVJjuJr7qbFR0g1Q5M+VBR5FOFJVK8z0Acc9idiygT//sJiUw3nUd+3CgVunUD7xVCfGud8Oyic6/Ph1i6goWiDLsTfCNilDQmS95lqMtkAUrU/mRgNx7EPkTpoyUHx9w3vsYxnOlkVGfhwhm+HBcxs0sShrqH46DhFEWT2OdqPHN5OO+N1l2W9AQCpvZdCTvXOj7G+KorzZgXN+D1wCfNjs09f6QE4gGOHPkHe3ErsW2tIl6wlK600X8yXR045im1Do7yi26W5qbiSAfemwXkLhLgo8ttcj1zXT54pUG2N//ZCj//kALBZ63H4na6eE0hit9VfbwsRMiiLIcuyNCmcZXDf/ef/NJClGW69RVhsmzL4RrS86XML1IyA6k8UymiQeNJllkVkQz+Or45w6xPVP9E6GmWucS6aQGVWE3K3thGmi0g464tf/FLhAUZQfcLj5pJtKIKFXgBopaJJtELLUxbZ0ye2ZekY4h2Rac2qs/obkMoxIFgs/JVEbzDLaX7h3fDTxUeGanrwizFu1ja33T9X0yBVddzdbhNO925Z/lGVz/krfnz7DWnEM2+jT6bvgNaJHjaHp+2dBUPcgQ2OToyiprevjxwJx7ERaEGYAogBqWrezhPQOiXETGNe3B1kH1lBSVUSCLYln1zpEgmvTli2FYqtT9EzLLBYZ977M8qlvsutWFGTQWyDZEUXISE5+ICpvZfBU6Bsu1moOCP/Ow/P6FDIBuiG3mO/2FAl/ZD27uGyDkKUuGjH/vOOy8by0R8Z3ItLmZL2B3TWKyXlsutPYdR98L5lDO7eshsMWbuVI816gFOfy4LpFDC3OoTrCxqkvvELizbe10h5/sbM7FwnqHmSt+QqOaYOiFhwNWlyzllbuLuemMfqYL2Xny8jXskJaQwfy6jpVwIc0sJU0LzMzkzGjx7D453e4aNBxmogWLf2rXeLiRtEzLbNYZDw9RthLjTzPRgokjTJensjEjp4KfV8VAAYUMgHqjvBLzw/tzuen1/8sgxFNRWSSuxs3AhnfiUibk/UGNvICeoOeNq+0CltdNbdv/oQrt63Carfz9cAzeXncDFLL09j+8JLWTf6z7eEcKEnTCFBAN11CaIhFmH5qIZb6Rvdsky34Nqc3RyrrdBHbiRhHQSxALz7lMKKEPpn2LnqmQ61dhVXgVmtXVu6ECf1KCAuxU99kYW1OgqNTmk4YcUEaycc3SkESqAYo3oCnQr9TwgipmbsfWWb+uR7vDX+ivwWlDDK+E5Hwk1XTGnkB3R3ratq/v9mGIy+hDex2ztu7mft+WEJiVSn745J4bvy1bE5znOuIi3tBVmAUFmLRncUio5+ICLUK595z1CZo+TeS2TrbYBpyXdglQlU2jlbp2VvcS/gMKEmnYm/6ofVzuNXO+QOPUmfvzrJscczAFUaeUV/l40PgGqB4A3oqcseqqrpZ8ueg5+LpCGRCUQTZj2zE/PPGA+QtQekpRJkRi3+OJSNf+1LLegMbcZnJjk1PK9eY9lcOhSOVx/PH08qK+NP69xmXl02tNZQ3T7+c90+7iLpQuQCS0WDIBLYR1EpSTEXz1jQdYsG0dF1KgZFN3htFhf0TT2ND7iFNVXZRmbh692LlMMuyxZ3RXGHkGa1qiCEqVMsEX1WvJcc2qrkHqgGKN6BH039WUZTuOFIz/6WqatsnYqVvlhVYyISiCLLgp5GHqCP+RFkAyRNB6S2z1DUzotqSw7Js45uM3oYpIuvp8y0vCY+9SClm634b1/70JddvXUFEYwMb04Yyf/y15MUluT0PIC2Wq6hr0PjpJwzoIaSTsFosjEkt1aQ0bi2MZ9KgZFaqha38/LIrzz5YojtIaWSTl1lqRtgml27NaU5/bPubHOT/pmlpJgCwl7J49lXSlNmOPqNLfo7jpjFaob/k5zjumOg8ZlTxClQDFG9AT8rmpGbqhWuBbxRF2Q+8C3yuquqDPl5fQCASivlllULud9lraeQhMvIAtWdBGMkp1nusp8yBRvmQlm7NYcGaL7hicDF3pzuE4oI1+4CLdZ9XZtoP2r2TxR+9Te+yIopt8bx01kx+GjaeIxIN3ghc/fTfqIXcNV5h7Z5DToJrwZovJB2k4Bv1+PPkbqs7I61Md5DSyCYvY6bsn3ia7k1GpvAcroyie7Q2eyo+qgeXSZ5HTxSR7/drYyQOl5tW0zeqeAWqAYo3oMunr6rqPkVRFuGoyP0dcA/wN0VRHlZV9VNfLjBQcBWK4Q+8LzxOFvw08hAZeYD8HUDyVpaCET6kT35aIxSKn/70re5zuropQo9WkvTmGuK/3UGjxcLSYRfw5thpVIVHsfgKBweQO66fFnSzhQs3/7AQi9BXv3bPIU0Dml0FxsjERIVOvxkknkNGGmZkkxdxNRnJhJEpPJ/+2pVbT9cKfW9x1rdsSiXVReRtWcfZvcP4fr/WNRYZqm1A3xHNPZjSMI1Aj0//ZuA6IAVHr9zxqqrmKYqSCmzFkXff6WFUEzD6EOl9gPwdQApElsKIHvuE48Mk4yK0uikam+j6xU/0eHc91qo6qk9VmH/u7Xwd0lVD+NXWnSRjlQRxdWWDm8YoruhpgDlTWugkMQOMBildqbtlVpyRTBjZu1JwLEUY7I6MdhRdeQLRpnTTGKhv1HIA3XKmlldoxqh+NDbspvDoBhKiqiiptpHSddwJKdTbgx5N/1zgcVVVv207qKpqgaIov/fJqoIQHRHi4H3zz98BpEBkKcg4a4xUrPZPPI2GX7ZT/OAcwtU8mmKiiH5qDqffPZcJVmdNT2bNLJ49XqOlL90q5v/rGiW2AFJjozRjVklK48Fj2gbtslTJxiYLIYKG5EYCrkbcaEYyYWTvih1xUNobCoRsU7pu9DF+KeqqYXF1xd7in6mvXUX35nKE7s3ssHuLe/iNodZf0OPTv87N35Z5dznBi44IcV+Yf/4OIAUiS8EaIhaKoaHibB9XNJSVkf/EY5S99QbhdjvdZsyi19+eJSxJHKg1Ys3IjpVl9VQKWj+ec8pvhMHSestwHLRWxyHb6MK0HgrAmKvEiBvNSFaP7F0xUkhnFLJNyRZ2jMp517T7fV9x7AcjzDx9AwgGH567zccXPXkDkaUgE4rnDPqN2+/Z7XaOfvRvDsy5n/qig9T17s8rE6/nk+g+DPlXhle4iGTHyrJ6RNq/LKVxcMpAHL2KjkNGzZBgS2J4r0keNceRu9FyNWNGs3pE74qjSMw3CoSnqaa+zOkPNphC/wSE6IXyVU/eQGQpuMsgkaFm9y72/eEuyteswhIZyZFb/8Dl9sHUW8OgmcNFFoD2RmGbEchSGnvFa9ML3TXs9rQ5jozoTGRddOQ3cYUvFYiKxqGIKJcd4+3DG/UJJwpMod9J4EvzNBAWjl6B1lRTQ+Hz8yh8fh72ujriplxI7+df5sxl26gXCGeRy8YbhW2yrJ7e8VrOGpmLSEQGl5EfR8iP8OAELcWwpyg8FiGkgC4QxBZA/28igy8ViOe+qyEqRJueWdNUy6yx7X/fG/UJJwpMod9JcDKZpy0oW/UN+/54D7V7dhOW2pPez75IwmXTsFgsbC/6Qfgdkcumo4VtbWsOQJzVc+mwNEcfgTY1DtuLygy1Oiw4lsrjq8M0FMOe1k/8cqgPaXE7NePZh/ronsMofKVAbC8qo7FJGyQODdFnlXnDkjlRYAr9ToKTyTytKyxg/0N/ouSTj8BqJemue+n5yFysXY4X3cjcMKmxNo0QbhFERgvbRDUH7nL9W1xMvz2lmiuHinvnfrVTm+2zv7QSSp3n2JBb7JYAUA+mj5zEgjVVukjbgh3eSDjwZy/pQKJTCn29uccnAvRey8lgntobGjj05hvkPfkXmo4dI3psOn0XvI5txEjNsTI3jEiAgnfocF03DhmR3tm9C4TjFytHmJ0+w2njKKmuFbp93t64WziHLP1RbhVcrLtSOphxItMi+BudTuifyDzXrjByLUbNU09dA/5GxY8Z7Lv3Tqp+3oo1IYE+L79B4g03YwkR0zOLXDYyAeqrQjNZpk+PaHGjmfCQct2V4LL+vyL3lbvnCI5zG7XHcRTMMEr14Q34IlvOH+h0Qv9E5rl2xcMrtgjH56zYKuVN0fPQnUgbY0NJCXlzH6X4nTfBbqfbNdfS66l5hPVo322lV4DK8sQ9fallLoeSGnEDlJIa7eso77YmbvwucmfI3ok5K7Y49Rf25nMQCIFohOrDU/gqW84fEKtJJzBOZJ5rV4i0UnC4KEbOX074A+8zcv5yaZWoDO42xmCB3W7n8NLFZI0eSvH/LSTylFNRvlpF/zf/qUvgizAkSRwoFQnKlpe6pOogdppaX+q9xT/rPt/Dk4cJx0Ml1km4oKmMbA4RlQCI3Rmyd0LUUB48fw68ce+CHe6y5YIdnU7oG3mxT2RkFZbS2Cb/3IjgD/aNsVrdgXrxBeTccj1NFcfoOfcphm7IJPaccz2aVyZARYLSGy/1jFH9WDx7PCNSEggNsTAiJYHFs8cLm5EDxEZox2VzLJiWLhxv4RFqqxSIqCDcwdPn4EQWiHpxImfLdTr3TmcK6PSKt0m1fVf4qsuWP9FUXU3Bs3/n4EvzsdfXE/fbi+kzfwERffp6ZX4jqZneeqnFXP/ilpIJNrEFI8ssEo2LXHcyyJ4vT5+DE1kg6sWJnC3X6TT9tpqR1YKTBnSi4Zmpo3Ufa7TLlgiB3BhLv/mK7PTTKHzuaUJ7JDFwyTIGffiZ1wR+C2aM6sfW+6dS+9xstt4/VfpcxEsEsDdeallG1fBekzRaurdcd73jbRqrQPZ8efoc+PLeBQvc/YbBjk6n6YN3AjrBkN0iykiQZaAY0c6CqQFEXX4e+x/8IyWffwJWK8n3/pHUOX/BGhPj97W0RUdSYPU+M7JMq4y8WI8D7DLXXUF5NTmPXSH8m7czXk6G9OETuZirUwp9TxFM2S2uG9i9n2YIm3tMGGBMiwo0eZy9oYGiha+R/+TjNFVUEHPmOPq89Bq2YSMCtqa26EgKrJFnRpRpNf09cV6/L113vsh4OZEFohGcqMVcARH6iqJMA65SVbV9ztMAIJjTPr/bI+4zunbPieMvrcjYSO69d1Kd9TPWrl3p+9qbdL/2BmnOfaBg5KX2xjPjjQB7sMS0TlSBeDLA70JfUZQFwG+An/x9br0I5uyWYF5be2g4epSm+U/z64rPwW6n++zr2Xz1/2/vTgOjKu89jn8nC0lAVtmXJFjxQQz12tiW3lIv11vt1WtFrdZi5Spq3YCybwqioKBBIAgiKCBuiFvlWtHqdUHqRa3GpUSuT13IImDYwxYm2+mLCRohAySznJk5v8+rzEnmnP+ZSX555jnPeZ6buObDLWyYsCIubhILJhzvS2Nb6UfrToqFrjuJTW609NcBq4AbXDj2cYnV0S2BGmK3tmAcx2HHk49Test42L6NjFNPIyt/Aaubd4+ZbrRQheN9aUwr/VjdSfH2+kn0+Jwga3uGqm5t3VGHbR5irX3fGDMAuNFa+7uj7aOgoCAbaNzwhTB4taicyes2HbH9zn/txrnZDd8HEC2xXFtDnKKNOHPz4OMPIT0d31XXwW8H4UtJ4YqXvuSL3UdO7XtymzRWnP8DF6ptunC9L68WlbN8w3Y2lvvp2TqNq/u0b/D5ifTaSUT1zM3NLaq/IWItfWvtUmBpOPaVk5NDWlpao5/X1ItTubnQ86SNMfUR+dC5xGJtDak5cIAteXfxzbw5UFVFm//6NZmz8inctv3b92Tjyv9v8LlFeyojfht9ONT//QrX+5KbC5MOG2TTUDfOxj3hfe2iMXVBtCTKuYRyHn6/n8LChq8zafROELH8ETmWawPY/ZfVFI8ZQWVxEc16ZJI5K5+2F1wY+Oa27d/+XCx1VYVjrphIvC/BunEidWPVsWpxexizhC62hktIXPN/Xcrngy7l80sHUrXpazqPGkvOB+u/C/zDxMpNYrE8V0ywUUG+ID8fqdfu0D+fUKb/kNjgSkvfWrsGWOPGsSX8aquq2PrAfDbddQe1+/dzws9+Hhhzf1rDoX5IrIw0CTYnzF8/f4VLHilxtWV7tJutnriyf9Reu1gexiyNo+4dCcned9dRPGIoFZ+uJ6XdiWTeO4/2v//v4x5zHwtdVcHmiqmq3vlt95NbI4uO1gUWzdcunocKy/epe8cDQp3PpSHVO3awcdgNfPbLs6j4dD3tr76Wvh9toEMM3mR1TL6G+8G37D1y8EC0p5+OlS4wr8xe6wVx9tcpjRXuvljHcdj22HLW/+g0ti9fSsZpfen9v2/Rc8FiUk48MczVR8fqf7RvcPtLtsMR26Ldsg02tXK0Px3Fyj8fCZ26dxJcOPtiKzZ8StHIoexb9zZJLVrQY0YeHW8aTlJqajhKdc2qDc0o3dX9iAXC/7bpyNatGy3bWOgCi5XrLxI6hX6CC0dfbM3+/Wy+ezpl8/Nxqqtpc8FAMmfNJa1HZrjKdFWfTq352yanwZA/nJdbtrHwz0dCp+6dBBdqX+yu1X+m8Mc/5Ju595LatRu9nllFr5XPJUzgQ/Cui2H9jevdKiLhppZ+gmvqrIv+0hJKxo1k94sv4EtJofOY8XSdMJnk5s0jVapr1HUhXqLQT3CNDbTaqirKFuSzeeZ0ag8coGX/s8iau4CMU/tEs+yoU9eFeIVC3wOON9D2rnub4pHDqNhQSEr7DmTl38+Jg67E5wt2/6eIxBuFvlC1fTtf3zaJ7Y8+DECHa66n++13ktKuncuViUi4KfQ9zKmtZftjyymdMpGanTvJ6Hs62fPu54Sf9HO7NBGJEIW+Rx0oXE/xqKHse2cdSSecQI97ZtPphqH4UvQrIZLI9BfuMTX79rH57ul8Mz8fampoO/ASMvPm0Kxbd7dLE5EoUOh7hOM47H7xBUrGjaTy61LSsnuSOec+2px7ntuliUgUKfQ9wF9cFBhz/9KL+FJT6TL+FrqOm0RSRobbpYlIlCn0E1htZSVl8+ey+e47qa2ooOVZAwJj7k1vt0sTEZco9BPU3rfXUjRyGAc/20BKh45kL1hMu98O0ph7DwjH0o+SuBT6CaZq2zZKJ09gxxOPgs9Hh+tupPvU6aS0bet2aRIFh5Z+POTQ0o+Agl8AhX7CcGpr2f7IMkpvm0TNrl00P/0Msubdzwln/sTt0iSKgi39uL70TYW+AAr9hHBg/ScUjRzK/vfeJallSzLz5tLx+ps05t6Dgi39uLui4e3iPUqFOFazdy+bZtxB2cL5gTH3l1xG5j2zadalq9uliUvaNO/IrgPfHLk9o6ML1Ugs0nz6cchxHHb+z/OsP7MvZfPzScvM4pRVqzn50ScV+B7Xt8e/N2q7eI9a+nHm4MavKBk7gvJXXsbXrBldJ06my5gJGnMvwHcXa9eXvsnuiq20ydDoHfm+qIa+MaY18DjQCmgGjLbWvhPNGuKVU1nJ5rwZbM6bgXPwIK0GnE3W3AWk9zrF7dIkxpzU4XSFvAQV7Zb+aOB1a22+McYATwI/inINcWfPW2/i3HQdm0qKSenYicyFS2h32eUacy8ijRbt0J8L+Osd+2CUjx9XqsrKKL11PDtWPgE+Hx2vv5lut00jpc3xrW8rInI4n+M4EdmxMeZaYNRhm4dYa983xnQGXgZGWmvfCraPgoKCbGBjRAqMYU5tLfx5Fc6DC2HfXjC98Y2eiK/3qW6XJiLxpWdubm5R/Q0Ra+lba5cCSw/fbozpC6wExh4t8OvLyckhLS2t0TUUFBSQm5vb6Oe5af8nH1E8Yhj7P3if5Fat6HbvPDr+4UY+/PjjuDuXhsTjexKMzsUdx5pmIp7O5WhCOQ+/309hYWGD34v2hdw+wDPA5dbaT6J57FhXs2cPX0+fytbF90NtLe0u+x09Zs6iWecubpcmEjM0zUToot2nPxNIB+YFruNSbq0dGOUaYorjOOz607OUTBxD1ZbNpJ3ci6w599H67HPcLk0k5miaidBFNfS9HvCHO/jVlxSPHs6e117Fl5ZG11un0mXUOJLS090uTSQmaZqJ0OnmLBfU+v1smZPHlnvvxvH7afUf55A1+z7ST+7ldmkiMU3TTIRO0zBE2Z43X+fTfmew+a47SGnbjpOWr+CUVS8p8EWOg6aZCJ1a+lFSVfYNJZPGsfPpJyEpiY43DqPblDtIad3a7dJE4oammQidQj/CnJoati5ZzKZpU6gpL6dF7plkzVtIi3/RjcgiTaFpJkKj0I+g/R8VUDRiKAc+/IDk1q3JmjOfDtdejy852e3SRMSjFPoRUF1ezqbpU9n64MLAmPvLryBzRh6pnTq7XZqIeJxCP4wcx2Hns09TOnEMVWXfkN7LkDV3Pq0GnO12aSIigEI/bA5+8TnFo4ax583X8aWn0+22aXQeMYakJkwfISISKQr9ENUePMiW2fewZU4ejt9P63N+Rebs+0g/6QdulyYicgSFfgjKX3+V4tF/xP/lF6R26UrmPXNoe/FvNM+9iMQshX4TVG7ZTOnEsex87mlISqLT0D/S7dbbSW7Vyu3SRESOSqHfCE5NDVsfWhQYc79nDy3O/HFgzP3pZ7hdmojIcVHoH6f9H34QGHP/UQHJbdqQNW8hHYZchy9JM1mISPxQ6B9D9e7dbLpjCluXLALH4cRBV9LjrjxSO2qCJxGJPwr9IBzHYeczKymZOJbqrWWkn9KbrPwFtDprgNuliYg0mUK/ARX/sJSMHs6eNW8ExtxPnR4Yc9+smduliYiERKFfT21FBVvuvZstc2fhVFbS+lfnkTX7PtKye7pdmohIWCj065S/9grFo4bj3/gVqd26k5k3l7YXXqQx9yKSUDwf+pWbN1EyYQy7nn8WkpPpNHwk3W6ZSnLLlm6XJiISdp4Nfae6mrLFC9l051Rq9+6lxU/7kT1vIc1zfuh2aSIiEePJ0N/3/nsUjxjKgb9/THLbtmTPX0T7q67RmHsRSXieCv3qXbv4+vbJbFv2IDgO7QdfTfdpM0nt0MHt0kREosIToe84DjueWkHppHFUb9tKeu8+ZOcvoGX/s9wuTUQkqqIa+saYFsAKoB2wHxhsrd0WyWNW2M8oHjWMvWvXkJSRQfdpM+g0bKTG3IuIJ0W7E/sPQIG19hfASmBypA5UW1FB7ZJFfNrvDPauXUOb8y8g54P1dBk9XoEvIp4V1Za+tTbfGHNoVfBMoCxixxp4Hqx7I/uneAAABVJJREFUm9QemWTOyqftBRdG6lAiInHD5zhORHZsjLkWGHXY5iHW2veNMW8AfYFzrLUfB9tHQUFBNrCxKcd3li/Bqa3FN2gwvoyMpuxCRCTe9czNzS2qvyFioX8sxpjewGprbdB1BQ+Ffk5ODmlNWGu2oKCA3NzcphcZQxLlXBLlPEDnEqsS5VxCOQ+/309hYSE0EPpR7dM3xkwyxgyue7gfqInm8UVEvC7aQzaXAY/Udf0kA0OifHwREU+L9oXcMuA/o3lMERH5juYdEBHxEIW+iIiHKPRFRDxEoS8i4iGxPuFaMkBlZWWTd+D3+8NWjNsS5VwS5TxA5xKrEuVcmnoe9TIz+fDvuXZz1vEoKCjoD/zV7TpEROLUL3Jzc9+uvyHWW/rvA78AtqAbuUREjlcy0IVAhn5PTLf0RUQkvHQhV0TEQxT6IiIeotAXEfEQhb6IiIco9EVEPCTWh2yGxI2F2CPBGNMaeBxoBTQDRltr33G3qtAYYy4GLrPWXuF2LY1ljEkCFgKnA37gOmvtF+5W1XTGmJ8C91hrB7hdS1MZY1IJTN2eDaQBd1prX3C1qCaqW1L2IcAQGKo+xFr7Zbj2n+gt/agtxB5ho4HXrbX/BlwN3O9uOaExxswDZhK/v38XAenW2p8BE4HZLtfTZMaY8cASIN3tWkJ0JbCj7m/9PGCBy/WE4tcA1tqfA7cBc8K583j9ozsu1tp84K66hxFdiD3C5gKL675OAQ66WEs4rANucruIEPQH/gJgrX0XONPdckLyJXCJ20WEwTPAlHqPq90qJFTW2lXA9XUPswhzbiVM987xLsQe/coa5xjn0ZlAN8/I6FfWeEc5l6eMMQNcKClcWgHl9R7XGGNSrLVxFzTW2ueMMdlu1xEqa+0+AGNMS+BZ4vdTPQDW2mpjzCPAxcCl4dx3woS+tXYpsDTI984+tBA7EHQh9lgQ7DyMMX0JdFGNtda+FfXCmuBo70mc2wO0rPc4KR4DP9EYY3oAzwMLrbUr3K4nVNbaq4wxE4D3jDF9rLX7w7HfhO7eSZSF2I0xfQh8fL3CWvuy2/UI/wecD2CM6Qesd7ccMcZ0Al4FJlhrl7ldTyiMMYONMZPqHh4AagljdiVMSz+IRFmIfSaBC23zjDEA5dbage6W5GnPA+cYY9YBPuL39yqR3AK0BaYYYw717Z9nra1wsaam+hPwsDFmLZAKjLTWhu06niZcExHxkITu3hERke9T6IuIeIhCX0TEQxT6IiIeotAXEfEQhb7IcTLGXGCMGe12HSKhSPRx+iLhFM9z7IgAGqcvHmeMeQxYa619qO7xGgJ3db532M/1Ad6oeziJwERY/QhM5DcfuBy43Vq7pm4umzXW2uy6O0UXAz0I3Fk5yVr7WsRPTCQIde+I1y0DBgMYY7KADocHPoC1dgOwCFhkrX24bnO6tbaPtfaBo+x/HrDMWpsLXAgsrpsUTMQV6t4Rr1sDdK1rnQ8GHm3Ec4/459CAXwK9jTHT6h6nEpj07+NGHEckbBT64mnWWqduCttBBLpozm3E0+vP6+IQmIcHAsF+SDJwtrV2J4AxpguwtekVi4RG3TsisBy4ESix1m4+ys9VE7yhtB04re7ri+ptfwO4Gb69LlAINA+lWJFQKPTF86y1pUAJgfA/mrXA740xwxv4Xh5wszHmQyCj3vbhQD9jzN+Bp4ArrbV7Q69apGk0ekc8zRjjA7oAbwE51lq/yyWJRJT69MXrfgM8ANxkrfUbY2bR8LKaH1hrr4tuaSLhp5a+iIiHqE9fRMRDFPoiIh6i0BcR8RCFvoiIhyj0RUQ85J+2vzmizqiaSQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_train = model.predict(x_train)\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "y_true_train_0 = y_train.to_numpy()[:,0]\n",
    "y_pred_train_0 = y_pred_train[:,0]\n",
    "\n",
    "y_true_test_0 = y_test.to_numpy()[: , 0]\n",
    "y_pred_test_0 = y_pred_test[:,0]\n",
    "\n",
    "plt.plot( y_true_train_0 , y_pred_train_0 , 'o', label = 'Train set ')\n",
    "plt.plot(y_true_test_0, y_pred_test_0 , 'o', label = 'Test set ')\n",
    "line = np.linspace(np.min(y_true_train_0) , np.max(y_true_train_0) , 100)\n",
    "plt.plot(line , line)\n",
    "plt.title('Prediction for SWAN_IN')\n",
    "plt.xlabel('y_true')\n",
    "plt.ylabel('y_pred')\n",
    "plt.legend()\n",
    "#plt.savefig('age_prediction_with_RF.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
