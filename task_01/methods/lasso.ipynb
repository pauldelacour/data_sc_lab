{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/pldelacour/Documents/PL_Ecole/data_sc_lab/data_sc_lab/task_01/pipelines'\n",
      "/Users/mathieuchevalley/Documents/Study/ETHZ/Fall Semester 2020/Data Science lab/data_sc_lab/task_01/methods\n"
     ]
    }
   ],
   "source": [
    "cd /Users/pldelacour/Documents/PL_Ecole/data_sc_lab/data_sc_lab/task_01/pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mathieuchevalley/Documents/Study/ETHZ/Fall Semester 2020/Data Science lab/data_sc_lab/task_01/pipelines\n"
     ]
    }
   ],
   "source": [
    "cd ../pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipynb.fs.full.tool_functions import *\n",
    "from yellowbrick.regressor import AlphaSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (66,68,80,81,82,83,84,95,96,97,98,99,110,111,112,113,114,125,126,127,128,129,140,141,142,144,155,156,157,159,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1384,1385,1387,1390,1391,1393,1396,1397,1399,1402,1403,1405,1408,1409,1411,1414,1415,1417,1420,1421,1423,1426,1427,1429,1432,1433,1435,1438,1439,1441,1444,1445,1447,1450,1451,1453,1456,1457,1459,1462,1463,1465,1468,1469,1471,1474,1475,1477,1480,1481,1483,1486,1487,1489,1492,1493,1495,1498,1499,1501,1504,1505,1507,1510,1511,1513,1516,1517,1519,1522,1523,1525,1528,1529,1531,1534,1535,1537,1540,1541,1543,1546,1547,1549,1552,1553,1555,1558,1559,1561,1564,1565,1567,1570,1571,1573,1576,1577,1579,1582,1583,1585,1588,1589,1591,1594,1595,1597,1600,1601,1603,1606,1607,1609,1612,1613,1615,1618,1619,1621,1624,1625,1627,1630,1631,1633,1636,1637,1639,1642,1643,1645,1648,1649,1651,1654,1655,1657,1660,1661,1663,1666,1667,1669,1672,1673,1675,1678,1679,1681,1684,1685,1687,1690,1691,1693,1696,1697,1699,1702,1703,1705,1708,1709,1711,1714,1715,1717,1720,1721,1723,1726,1727,1729,1732,1733,1735,1738,1739,1741,1744,1745,1747,1750,1751,1753,1756,1757,1759,1762,1763,1765,1768,1769,1771,1774,1775,1777,1780,1781,1783,1786,1787,1789,1792,1793,1795,1798,1799,1801,1804,1805,1807,1810,1811,1813,1816,1817,1819,1822,1823,1825,1828,1829,1831,1834,1835,1837,1840,1841,1843,1846,1847,1849,1852,1853,1855,1858,1859,1861,1882,1883,1884,1917,1918,1919,1952,1953,1954,1955,1987,1988,1989,1990,2022,2023,2024,2025,2026,2057,2058,2059,2060,2061,2092,2093,2094,2095,2096,2097,2127,2128,2129,2130,2131,2132,2162,2163,2164,2165,2166,2167,2168,2197,2198,2199,2200,2201,2202,2203,2232,2233,2234,2235,2236,2237,2238,2239,2267,2268,2269,2270,2271,2272,2273,2274,2302,2303,2304,2305,2306,2307,2308,2309,2337,2338,2339,2340,2341,2342,2343,2344,2477,2478,2479,2512,2513,2514,2547,2548,2549,2550,2582,2583,2584,2585,2617,2618,2619,2620,2621,2652,2653,2654,2655,2656,2687,2688,2689,2690,2691,2692,2722,2723,2724,2725,2726,2727,2757,2758,2759,2760,2761,2762,2763,2792,2793,2794,2795,2796,2797,2798,2827,2828,2829,2830,2831,2832,2833,2834,2862,2863,2864,2865,2866,2867,2868,2869,2897,2898,2899,2900,2901,2902,2903,2904,2932,2933,2934,2935,2936,2937,2938,2939,3819,3826,3866,3933,4037,4055,4059,4063,4067,4071,4075,4079,4084,4085,4086,4087,4088,4091,4092,4094,4095,4096,4608,4616,4648,4649,4664,4665,4667,4683,4690,4691,4692,4693,4739,4800,5002,5010,5018,5026,5042,5240,5282,5386,5433,5443,5463,5466,5467,5468,5470,5478,5479,5481,5482,5483,5484,5485,5486,5487,5488,5489,5490,5491,5492,5495,5499,5503,5507,5511,5515,5517,5518,5519,5520,5521,5522,5523,5524,5532,5535,5536,5537,5539,5540,5548,5549,5551,5552,5553,5554,5555,5556,5557,5558,5559,5560,5561,5562,5565,5569,5573,5577,5581,5586,5587,5588,5589,5590,5591,5592,5593,5594,5601,5604,5605,5606,5608,5616,5617,5619,5620,5621,5622,5623,5624,5625,5626,5627,5628,5629,5630,5633,5636,5637,5638,5640,5648,5649,5651,5652,5653,5654,5655,5656,5657,5658,5659,5660,5661,5662,5665,5668,5669,5670,5672,5680,5681,5683,5684,5685,5686,5687,5688,5689,5690,5691,5692,5693,5694,5697,5700,5701,5702,5704,5712,5713,5715,5716,5717,5718,5719,5720,5721,5722,5723,5724,5725,5726,5729,5732,5733,5734,5736,5744,5745,5747,5748,5749,5750,5751,5752,5753,5754,5755,5756,5757,5758,5759,5760,5761,5762,5763,5764,5768,5772,5776,5780,5784,5788,5792,5796,5800,5804,5808,5812,5816,5820,5869,5877,5881,5885,5889,5893,5897,6538,6539,6540,6541,6542,6555,6556,6557,6558,6559,6572,6573,6574,6575,6576,6589,6590,6591,6592,6593,6606,6607,6608,6609,6610,6623,6624,6625,6626,6627,6636,6644,6650,6653,6682,6701,6738,6768) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_beha = pd.read_csv('../../../data/Behavioral/AllData.csv')#, nrows=1000)\n",
    "\n",
    "df_psd_cluster = pd.read_csv(\"../../../data/EEG/RestingEEG_PSD_Cluster.csv\") #, nrows=1000)\n",
    "df_psd_channel = pd.read_csv(\"../../../data/EEG/RestingEEG_PSD_Channel.csv\") #, nrows=5)\n",
    "df_spectro_cluster = pd.read_csv(\"../../../data/EEG/RestingEEG_Spectro_Cluster.csv\") #, nrows=1000)\n",
    "df_spectro_channel = pd.read_csv(\"../../../data/EEG/RestingEEG_Spectro_Channel.csv\") #, nrows=5)\n",
    "\n",
    "df_microstate = pd.read_csv(\"../../../data/EEG/RestingEEG_Microstates.csv\") #, nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>NDARCF462HNM</td>\n",
       "      <td>14.216632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>NDARFC233RND</td>\n",
       "      <td>9.153661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>NDARDT800YVF</td>\n",
       "      <td>17.510381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>NDARZT011LBZ</td>\n",
       "      <td>7.760209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>NDARKV482FU9</td>\n",
       "      <td>10.977298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2088</td>\n",
       "      <td>NDARAV069HGT</td>\n",
       "      <td>13.896189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2089</td>\n",
       "      <td>NDARZC497BFU</td>\n",
       "      <td>17.419917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>NDARDZ737LG9</td>\n",
       "      <td>13.031143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2094</td>\n",
       "      <td>NDARRT283RHB</td>\n",
       "      <td>10.712069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2095</td>\n",
       "      <td>NDARYG879ZM4</td>\n",
       "      <td>13.701346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Patient_ID        Age\n",
       "9     NDARCF462HNM  14.216632\n",
       "11    NDARFC233RND   9.153661\n",
       "22    NDARDT800YVF  17.510381\n",
       "25    NDARZT011LBZ   7.760209\n",
       "26    NDARKV482FU9  10.977298\n",
       "...            ...        ...\n",
       "2088  NDARAV069HGT  13.896189\n",
       "2089  NDARZC497BFU  17.419917\n",
       "2090  NDARDZ737LG9  13.031143\n",
       "2094  NDARRT283RHB  10.712069\n",
       "2095  NDARYG879ZM4  13.701346\n",
       "\n",
       "[513 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract relevant info from the Behavioral data \n",
    "y_labels = df_beha[[\"Patient_ID\", \"Age\", \"DX_01_Cat\"]]\n",
    "y_labels_healthy = y_labels[y_labels[\"DX_01_Cat\"].str.contains(\"No Diagnosis Given\") == True]\n",
    "\n",
    "y_labels = y_labels[[\"Patient_ID\", \"Age\"]]\n",
    "y_labels_healthy = y_labels_healthy[[\"Patient_ID\", \"Age\"]]\n",
    "y_labels_healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original lengths: 1485(psd), 1485(spectro), 1108(micro)\n",
      "Only healthy people, resulting lengths: 174(psd), 174(spectro), 128(micro)\n",
      "Replace NaN by median, resulting lenghts: 174(psd), 174(spectro), 128(micro)\n"
     ]
    }
   ],
   "source": [
    "df_psd_cluster.rename(columns={'id': 'Patient_ID'}, inplace=True)\n",
    "df_spectro_cluster.rename(columns={'id': 'Patient_ID'}, inplace=True)\n",
    "df_microstate.rename(columns={'id': 'Patient_ID'}, inplace=True)\n",
    "print(\"Original lengths: \" + str(len(df_psd_cluster)) + \"(psd), \" + \\\n",
    "     str(len(df_spectro_cluster)) + \"(spectro), \" + str(len(df_microstate)) + \"(micro)\")\n",
    "\n",
    "# Aggregate with label\n",
    "df_label_psd_cluster = pd.merge(y_labels_healthy, df_psd_cluster, on='Patient_ID')\n",
    "df_label_spectro_cluster = pd.merge(y_labels_healthy, df_spectro_cluster, on='Patient_ID')\n",
    "df_label_microstate = pd.merge(y_labels_healthy, df_microstate, on='Patient_ID')\n",
    "print(\"Only healthy people, resulting lengths: \" + str(len(df_label_psd_cluster)) + \"(psd), \" + \\\n",
    "     str(len(df_label_spectro_cluster)) + \"(spectro), \" + str(len(df_label_microstate)) + \"(micro)\")\n",
    "\n",
    "# Drop NaN values\n",
    "df_label_psd_cluster = fill_with_median(df_label_psd_cluster)\n",
    "df_label_spectro_cluster = fill_with_median(df_label_spectro_cluster)\n",
    "df_label_microstate = fill_with_median(df_label_microstate)\n",
    "print(\"Replace NaN by median, resulting lenghts: \" + str(len(df_label_psd_cluster)) + \"(psd), \" + \\\n",
    "     str(len(df_label_spectro_cluster)) + \"(spectro), \" + str(len(df_label_microstate)) + \"(micro)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Split into Train and Test data ----\n",
      "\n",
      "Test lengths: 34(psd), 34(spectro), 25(micro)\n",
      "\n",
      "---- Feature selection by correlation ----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Train and Test data \n",
    "print()\n",
    "print(\"---- Split into Train and Test data ----\")\n",
    "print()\n",
    "(X_train_psd, y_train_psd, X_test_psd, y_test_psd) = \\\n",
    "                                                    train_test_split(df_label_psd_cluster, test_ratio)\n",
    "(X_train_spe, y_train_spe, X_test_spe, y_test_spe) = \\\n",
    "                                                    train_test_split(df_label_spectro_cluster, test_ratio)\n",
    "(X_train_mic, y_train_mic, X_test_mic, y_test_mic) = \\\n",
    "                                                    train_test_split(df_label_microstate, test_ratio)\n",
    "\n",
    "print(\"Test lengths: \" + str(len(y_test_psd)) + \"(psd), \" + \\\n",
    "     str(len(y_test_spe)) + \"(spectro), \" + str(len(y_test_mic)) + \"(micro)\")\n",
    "\n",
    "# Feature selection by correlation\n",
    "print()\n",
    "print(\"---- Feature selection by correlation ----\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphas = np.logspace(1,-10 , 100)\n",
    "#alphas = np.logspace(-4, -0.5, 30)\n",
    "#alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001     , 0.00129155, 0.0016681 , 0.00215443, 0.00278256,\n",
       "       0.00359381, 0.00464159, 0.00599484, 0.00774264, 0.01      ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.logspace(-3, -2, 10)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train_psd.loc[:,X_train_psd.columns != 'Patient_ID']\n",
    "y_train = y_train_psd.loc[:,y_train_psd.columns != 'Patient_ID']\n",
    "x_test = X_test_psd.loc[:,X_train_psd.columns != 'Patient_ID']\n",
    "y_test = y_test_psd.loc[:,y_train_psd.columns != 'Patient_ID']\n",
    "#x_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:1100: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.53186978754675, tolerance: 0.12412559113995626\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.606876662943364, tolerance: 0.12412559113995626\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.0505118751843, tolerance: 0.12412559113995626\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.30039785234415, tolerance: 0.12412559113995626\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.79633885110946, tolerance: 0.12412559113995626\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31.289120482374233, tolerance: 0.12412559113995626\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.46090803857737, tolerance: 0.12412559113995626\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.884369270981733, tolerance: 0.12412559113995626\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.09496820542796, tolerance: 0.12412559113995626\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.435517436346185, tolerance: 0.12412559113995626\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.4214680016145, tolerance: 0.15207931370371613\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.64543135764799, tolerance: 0.15207931370371613\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.94813077201323, tolerance: 0.15207931370371613\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.80833580928648, tolerance: 0.15207931370371613\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.07131557876397, tolerance: 0.15207931370371613\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.750421733693926, tolerance: 0.15207931370371613\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.23277493214053, tolerance: 0.15207931370371613\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.32286758467665, tolerance: 0.15207931370371613\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.961149371143122, tolerance: 0.15207931370371613\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.097252383502614, tolerance: 0.15207931370371613\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.690322758112856, tolerance: 0.156106151114558\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.746780165465324, tolerance: 0.156106151114558\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 52.60345228656567, tolerance: 0.156106151114558\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.181193301183086, tolerance: 0.156106151114558\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.36590524108914, tolerance: 0.156106151114558\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.88640191498746, tolerance: 0.156106151114558\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.51127691054821, tolerance: 0.156106151114558\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.05772284222361, tolerance: 0.156106151114558\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.7372363851252, tolerance: 0.156106151114558\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.790208384371653, tolerance: 0.156106151114558\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.457232739586757, tolerance: 0.12789081293619542\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.312101226919552, tolerance: 0.12789081293619542\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.801356169787908, tolerance: 0.12789081293619542\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.013266271139095, tolerance: 0.12789081293619542\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21.203264237174437, tolerance: 0.12789081293619542\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.757742075786037, tolerance: 0.12789081293619542\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.864260003928166, tolerance: 0.12789081293619542\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.39262267843203, tolerance: 0.12789081293619542\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.96397501414736, tolerance: 0.12789081293619542\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25.793201039316713, tolerance: 0.12789081293619542\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 76.84488605267592, tolerance: 0.16147585053687494\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.21011715287587, tolerance: 0.16147585053687494\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.80283946546322, tolerance: 0.16147585053687494\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.80787299548413, tolerance: 0.16147585053687494\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.589217979035254, tolerance: 0.16147585053687494\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.54019936759626, tolerance: 0.16147585053687494\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.0988613759758, tolerance: 0.16147585053687494\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.85570416764601, tolerance: 0.16147585053687494\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.429530160816483, tolerance: 0.16147585053687494\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25.14713308734774, tolerance: 0.16147585053687494\n",
      "  positive)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.68848880936628, tolerance: 0.18081963440430823\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1465b9a10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LassoCV(cv=5, random_state=0, alphas = alphas, max_iter=3000)\n",
    "#reg.fit(x_train, y_train)\n",
    "visualizer = AlphaSelection(reg)\n",
    "visualizer.fit(x_train, y_train)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha =  0.01\n",
      "# of coef before =  2040\n",
      "# of coef after =  128\n",
      "MSE =  [100.10555148 154.4188349  218.94664926 294.13901786 390.96366632\n",
      " 483.79684431 569.87188129 647.12232517 717.42651395 778.00012962]\n"
     ]
    }
   ],
   "source": [
    "#print(visualizer.alpha_)\n",
    "#reg = visualizer\n",
    "print(\"Best Alpha = \", visualizer.alpha_)\n",
    "#best_alpha = reg.alpha\n",
    "print(\"# of coef before = \", len(visualizer.coef_))\n",
    "print(\"# of coef after = \" , np.sum(visualizer.coef_!=0))\n",
    "print('MSE = ' , np.mean(visualizer.mse_path_ , axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = visualizer.coef_!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eyesclosed_psd_01dot00hz_mfront</th>\n",
       "      <th>eyesclosed_psd_01dot00hz_rfront</th>\n",
       "      <th>eyesclosed_psd_01dot00hz_lpari</th>\n",
       "      <th>eyesclosed_psd_01dot00hz_mpari</th>\n",
       "      <th>eyesclosed_psd_01dot00hz_rpari</th>\n",
       "      <th>eyesclosed_psd_01dot50hz_lfront</th>\n",
       "      <th>eyesclosed_psd_01dot50hz_mfront</th>\n",
       "      <th>eyesclosed_psd_01dot50hz_mpari</th>\n",
       "      <th>eyesclosed_psd_01dot50hz_rpari</th>\n",
       "      <th>eyesclosed_psd_02dot00hz_rfront</th>\n",
       "      <th>...</th>\n",
       "      <th>eyesopen_psd_10dot00hz_mpari</th>\n",
       "      <th>eyesopen_psd_10dot50hz_lfront</th>\n",
       "      <th>eyesopen_psd_10dot50hz_rpari</th>\n",
       "      <th>eyesopen_psd_11dot00hz_lfront</th>\n",
       "      <th>eyesopen_psd_11dot00hz_mpari</th>\n",
       "      <th>eyesopen_psd_12dot00hz_rpari</th>\n",
       "      <th>eyesopen_psd_12dot50hz_rpari</th>\n",
       "      <th>eyesopen_psd_14dot50hz_mpari</th>\n",
       "      <th>eyesopen_psd_28dot50hz_mpari</th>\n",
       "      <th>eyesopen_psd_33dot50hz_mpari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>3.093369</td>\n",
       "      <td>3.532940</td>\n",
       "      <td>3.823570</td>\n",
       "      <td>5.645943</td>\n",
       "      <td>3.165222</td>\n",
       "      <td>1.982113</td>\n",
       "      <td>2.889688</td>\n",
       "      <td>4.939520</td>\n",
       "      <td>2.870843</td>\n",
       "      <td>2.346684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436062</td>\n",
       "      <td>0.173794</td>\n",
       "      <td>0.255782</td>\n",
       "      <td>0.129409</td>\n",
       "      <td>0.321147</td>\n",
       "      <td>0.153420</td>\n",
       "      <td>0.135904</td>\n",
       "      <td>0.168605</td>\n",
       "      <td>0.046417</td>\n",
       "      <td>0.037680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>8.824072</td>\n",
       "      <td>7.856013</td>\n",
       "      <td>8.493099</td>\n",
       "      <td>9.119003</td>\n",
       "      <td>12.040098</td>\n",
       "      <td>8.269384</td>\n",
       "      <td>9.025446</td>\n",
       "      <td>9.459177</td>\n",
       "      <td>12.478681</td>\n",
       "      <td>5.762295</td>\n",
       "      <td>...</td>\n",
       "      <td>3.649563</td>\n",
       "      <td>1.300103</td>\n",
       "      <td>2.489741</td>\n",
       "      <td>0.887655</td>\n",
       "      <td>1.124435</td>\n",
       "      <td>0.729943</td>\n",
       "      <td>0.610726</td>\n",
       "      <td>0.512440</td>\n",
       "      <td>0.041118</td>\n",
       "      <td>0.029757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>12.779590</td>\n",
       "      <td>8.482489</td>\n",
       "      <td>11.761118</td>\n",
       "      <td>25.732970</td>\n",
       "      <td>11.497741</td>\n",
       "      <td>12.278763</td>\n",
       "      <td>12.468844</td>\n",
       "      <td>25.536666</td>\n",
       "      <td>10.814782</td>\n",
       "      <td>6.501963</td>\n",
       "      <td>...</td>\n",
       "      <td>1.630101</td>\n",
       "      <td>1.044831</td>\n",
       "      <td>0.908202</td>\n",
       "      <td>0.943526</td>\n",
       "      <td>1.502082</td>\n",
       "      <td>0.585680</td>\n",
       "      <td>0.510318</td>\n",
       "      <td>0.515332</td>\n",
       "      <td>0.106396</td>\n",
       "      <td>0.095202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>4.097884</td>\n",
       "      <td>1.494475</td>\n",
       "      <td>2.092393</td>\n",
       "      <td>5.736902</td>\n",
       "      <td>1.127765</td>\n",
       "      <td>3.505047</td>\n",
       "      <td>3.404378</td>\n",
       "      <td>4.634194</td>\n",
       "      <td>0.919095</td>\n",
       "      <td>0.811373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236685</td>\n",
       "      <td>0.089585</td>\n",
       "      <td>0.041344</td>\n",
       "      <td>0.087364</td>\n",
       "      <td>0.181349</td>\n",
       "      <td>0.029663</td>\n",
       "      <td>0.027665</td>\n",
       "      <td>0.121753</td>\n",
       "      <td>0.099719</td>\n",
       "      <td>0.116175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>16.370740</td>\n",
       "      <td>15.084291</td>\n",
       "      <td>18.365652</td>\n",
       "      <td>20.572433</td>\n",
       "      <td>22.367883</td>\n",
       "      <td>14.457712</td>\n",
       "      <td>15.516250</td>\n",
       "      <td>20.606551</td>\n",
       "      <td>24.348495</td>\n",
       "      <td>10.220858</td>\n",
       "      <td>...</td>\n",
       "      <td>2.571540</td>\n",
       "      <td>1.648308</td>\n",
       "      <td>3.896273</td>\n",
       "      <td>1.550827</td>\n",
       "      <td>2.465413</td>\n",
       "      <td>2.715528</td>\n",
       "      <td>2.355627</td>\n",
       "      <td>0.724543</td>\n",
       "      <td>0.278544</td>\n",
       "      <td>0.050496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    eyesclosed_psd_01dot00hz_mfront  eyesclosed_psd_01dot00hz_rfront  \\\n",
       "34                         3.093369                         3.532940   \n",
       "35                         8.824072                         7.856013   \n",
       "36                        12.779590                         8.482489   \n",
       "37                         4.097884                         1.494475   \n",
       "38                        16.370740                        15.084291   \n",
       "\n",
       "    eyesclosed_psd_01dot00hz_lpari  eyesclosed_psd_01dot00hz_mpari  \\\n",
       "34                        3.823570                        5.645943   \n",
       "35                        8.493099                        9.119003   \n",
       "36                       11.761118                       25.732970   \n",
       "37                        2.092393                        5.736902   \n",
       "38                       18.365652                       20.572433   \n",
       "\n",
       "    eyesclosed_psd_01dot00hz_rpari  eyesclosed_psd_01dot50hz_lfront  \\\n",
       "34                        3.165222                         1.982113   \n",
       "35                       12.040098                         8.269384   \n",
       "36                       11.497741                        12.278763   \n",
       "37                        1.127765                         3.505047   \n",
       "38                       22.367883                        14.457712   \n",
       "\n",
       "    eyesclosed_psd_01dot50hz_mfront  eyesclosed_psd_01dot50hz_mpari  \\\n",
       "34                         2.889688                        4.939520   \n",
       "35                         9.025446                        9.459177   \n",
       "36                        12.468844                       25.536666   \n",
       "37                         3.404378                        4.634194   \n",
       "38                        15.516250                       20.606551   \n",
       "\n",
       "    eyesclosed_psd_01dot50hz_rpari  eyesclosed_psd_02dot00hz_rfront  ...  \\\n",
       "34                        2.870843                         2.346684  ...   \n",
       "35                       12.478681                         5.762295  ...   \n",
       "36                       10.814782                         6.501963  ...   \n",
       "37                        0.919095                         0.811373  ...   \n",
       "38                       24.348495                        10.220858  ...   \n",
       "\n",
       "    eyesopen_psd_10dot00hz_mpari  eyesopen_psd_10dot50hz_lfront  \\\n",
       "34                      0.436062                       0.173794   \n",
       "35                      3.649563                       1.300103   \n",
       "36                      1.630101                       1.044831   \n",
       "37                      0.236685                       0.089585   \n",
       "38                      2.571540                       1.648308   \n",
       "\n",
       "    eyesopen_psd_10dot50hz_rpari  eyesopen_psd_11dot00hz_lfront  \\\n",
       "34                      0.255782                       0.129409   \n",
       "35                      2.489741                       0.887655   \n",
       "36                      0.908202                       0.943526   \n",
       "37                      0.041344                       0.087364   \n",
       "38                      3.896273                       1.550827   \n",
       "\n",
       "    eyesopen_psd_11dot00hz_mpari  eyesopen_psd_12dot00hz_rpari  \\\n",
       "34                      0.321147                      0.153420   \n",
       "35                      1.124435                      0.729943   \n",
       "36                      1.502082                      0.585680   \n",
       "37                      0.181349                      0.029663   \n",
       "38                      2.465413                      2.715528   \n",
       "\n",
       "    eyesopen_psd_12dot50hz_rpari  eyesopen_psd_14dot50hz_mpari  \\\n",
       "34                      0.135904                      0.168605   \n",
       "35                      0.610726                      0.512440   \n",
       "36                      0.510318                      0.515332   \n",
       "37                      0.027665                      0.121753   \n",
       "38                      2.355627                      0.724543   \n",
       "\n",
       "    eyesopen_psd_28dot50hz_mpari  eyesopen_psd_33dot50hz_mpari  \n",
       "34                      0.046417                      0.037680  \n",
       "35                      0.041118                      0.029757  \n",
       "36                      0.106396                      0.095202  \n",
       "37                      0.099719                      0.116175  \n",
       "38                      0.278544                      0.050496  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.loc[:,features].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_extract = x_train.loc[:,features]\n",
    "x_test_extract = x_test.loc[:,features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-66.77875135153363"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(x_train_extract, y_train)\n",
    "reg.score(x_test_extract , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age    738.892498\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = np.mean((reg.predict(x_test_extract) - y_test)**2)\n",
    "mse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with average baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean =  11.290413743421546\n",
      "Median =  12.972380931427482\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean = np.mean((np.mean(y_train) - y_test)**2)\n",
    "median = np.mean((np.median(y_train) - y_test)**2)\n",
    "print(\"Mean = \" , mean[0] )\n",
    "print('Median = ' , median[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF , DotProduct, Matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5, 1. , 1.5, 2. ])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengthscale = np.linspace(0.1,1, num = 5)\n",
    "lengthscale\n",
    "sigma_0 = np.linspace(0,2 , num = 5)\n",
    "sigma_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/_gpr.py:494: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n",
      "/Users/pldelacour/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/kernels.py:255: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(np.hstack(theta))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                                                kernel=None,\n",
       "                                                n_restarts_optimizer=0,\n",
       "                                                normalize_y=False,\n",
       "                                                optimizer='fmin_l_bfgs_b',\n",
       "                                                random_state=None),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [0.01, 0.1, 1, 10],\n",
       "                         'kernel': (RBF(length_scale=0.1) + DotProduct(sigma_0=0),\n",
       "                                    RBF(length_scale=0.1) + DotProduct(s...\n",
       "                                    RBF(length_scale=0.775) + DotProduct(sigma_0=1.5),\n",
       "                                    RBF(length_scale=0.775) + DotProduct(sigma_0=2),\n",
       "                                    RBF(length_scale=1) + DotProduct(sigma_0=0),\n",
       "                                    RBF(length_scale=1) + DotProduct(sigma_0=0.5),\n",
       "                                    RBF(length_scale=1) + DotProduct(sigma_0=1),\n",
       "                                    RBF(length_scale=1) + DotProduct(sigma_0=1.5),\n",
       "                                    RBF(length_scale=1) + DotProduct(sigma_0=2))},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp = GaussianProcessRegressor()\n",
    "tuple_kernel = list()\n",
    "for i in range(len(lengthscale)):\n",
    "    for j in range(len(sigma_0)):\n",
    "        tuple_kernel.append(RBF(length_scale = lengthscale[i]) + DotProduct(sigma_0 = sigma_0[j]))\n",
    "\n",
    "tuple_kernel = tuple(tuple_kernel)\n",
    "parameters = {'kernel' : tuple_kernel, 'alpha':[0.01,0.1,1,10]}\n",
    "gp_model = GridSearchCV(gp, parameters ,cv =3)\n",
    "gp_model.fit(x_train_extract , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score =  0.45157904568933277\n",
      "Best param  {'alpha': 10, 'kernel': RBF(length_scale=1) + DotProduct(sigma_0=0.5)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score = \" , gp_model.best_score_)\n",
    "print('Best param ' , gp_model.best_params_)\n",
    "gp_model.best_estimator_\n",
    "best_param_gp = gp_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE for GP =  7.984468549719948\n"
     ]
    }
   ],
   "source": [
    "gp_final = GaussianProcessRegressor(kernel = best_param_gp['kernel'] , alpha = best_param_gp['alpha'])\n",
    "gp_final.fit(x_train_extract , y_train)\n",
    "y_predicted_gp = gp_final.predict(x_test_extract)\n",
    "test_mse_gp = sklearn.metrics.mean_squared_error(y_test ,y_predicted_gp)\n",
    "print('Test MSE for GP = ' , test_mse_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.020125273380868"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVR()\n",
    "clf.fit(x_train_extract, y_train)\n",
    "sklearn.metrics.mean_squared_error(y_test , clf.predict(x_test_extract))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross val\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'kernel': ('rbf', 'poly', 'linear')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr= svm.SVR()\n",
    "parameters = {'kernel' : ( 'rbf' , 'poly', 'linear' ), 'C':[0.1, 1,10,100]}\n",
    "clf = GridSearchCV(svr, parameters ,cv =3)\n",
    "clf.fit(x_train_extract , y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=0.1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Best score =  0.17388375718743496\n",
      "Best param =  {'C': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "best_param = clf.best_params_\n",
    "print(\"Best score = \" , clf.best_score_)\n",
    "print(\"Best param = \" , best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST MSE =  13.507407601289081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svr_final = svm.SVR(kernel = best_param['kernel'] , C = best_param['C'])\n",
    "svr_final.fit(x_train_extract , y_train)\n",
    "test_mse_svm = sklearn.metrics.mean_squared_error(y_test , svr_final.predict(x_test_extract))\n",
    "print('TEST MSE = ', test_mse_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
