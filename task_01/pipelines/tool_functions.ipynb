{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool functions for all approaches in Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataframe, test_train_ratio):\n",
    "\n",
    "    total_samples = len(dataframe.index)\n",
    "    nsamples_test = int(test_train_ratio*total_samples)\n",
    "    dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    test = dataframe.iloc[:nsamples_test]\n",
    "    X_test = test.drop(['Age'], axis=1)\n",
    "    y_test = test[['Patient_ID', 'Age']]\n",
    "\n",
    "    train = dataframe.iloc[nsamples_test:]\n",
    "    X_train = train.drop(['Age'], axis=1)\n",
    "    y_train = train[['Patient_ID','Age']]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select_by_correlation(X_train, y_train, nb_features):\n",
    "    corr = X_train.corrwith(y_train['Age'], axis=0, method='pearson')\n",
    "    feature_select = pd.DataFrame(corr.iloc[(-corr.abs()).argsort()][:nb_features])\n",
    "    best_feature_names = feature_select.index.values\n",
    "    \n",
    "    return feature_select, best_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_by_correlation(X_train, y_train, X_test, nb_features):\n",
    "    feature_select, best_feature_names = feature_select_by_correlation(X_train, y_train, nb_features)\n",
    "    best_feature_names = np.insert(best_feature_names, 0, 'Patient_ID')\n",
    "    return X_train[best_feature_names], X_test[best_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_simple_linear_regression(X_train_feature_extracted, y_train, nb_cv):\n",
    "\n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train_feature_extracted, y_train)\n",
    "\n",
    "    # Evaluate performance using cross-validation \n",
    "    scores = cross_val_score(regr, X_train_feature_extracted, y_train, scoring=\"neg_mean_squared_error\", cv=nb_cv)\n",
    "    train_mse = np.mean(-scores)\n",
    "\n",
    "    # Results\n",
    "    print(\"----- Train results -------\")\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    print('Mean squared error (cross-validation): %.2f'\n",
    "          % train_mse)\n",
    "    print()\n",
    "\n",
    "    return regr, train_mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_regression(X_train_feature_extracted, X_test_feature_extracted, y_train, y_test, nb_cv):\n",
    "\n",
    "    regr, train_mse = fit_simple_linear_regression(X_train_feature_extracted, y_train, nb_cv)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = regr.predict(X_test_feature_extracted)\n",
    "    test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print(\"----- Test results --------\")\n",
    "    print(\"Number of test samples: \", len(y_pred))\n",
    "    print('Mean squared error: %.2f'\n",
    "          % test_mse)\n",
    "    \n",
    "    return regr, train_mse, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slr_with_correlation(aggregated_dataframe, test_ratio, nb_features_extracted, nb_cv):\n",
    "    \n",
    "    # Define Train and Test data \n",
    "    print()\n",
    "    print(\"---- Split into Train and Test data ----\")\n",
    "    print()\n",
    "    (X_train_inter, y_train_inter, X_test_inter, y_test_inter) = \\\n",
    "                                                    train_test_split(aggregated_dataframe, test_ratio)\n",
    "\n",
    "    print(\"Length of the train set:\")\n",
    "    print(len(y_train_inter))\n",
    "    print(\"Length of the test set:\")\n",
    "    print(len(y_test_inter))\n",
    "    \n",
    "    # Feature selection by correlation\n",
    "    print()\n",
    "    print(\"---- Feature selection by correlation ----\")\n",
    "    print()\n",
    "    feature_select, best_feature_names = \\\n",
    "                        feature_select_by_correlation(X_train_inter, y_train_inter, nb_features_extracted)\n",
    "    print(feature_select)\n",
    "    \n",
    "    X_train_inter_feature_extracted, X_test_inter_feature_extracted = \\\n",
    "               feature_selection_by_correlation(X_train_inter, y_train_inter, X_test_inter, nb_features_extracted)\n",
    "    \n",
    "    # Simple Linear Regression\n",
    "    print()\n",
    "    print(\"---- Simple Linear Regression ----\")\n",
    "    print()\n",
    "    \n",
    "    # Remove key for linear regression\n",
    "    X_train_inter_feature_extracted = X_train_inter_feature_extracted.drop(['Patient_ID'], axis=1, errors='ignore')\n",
    "    X_test_inter_feature_extracted = X_test_inter_feature_extracted.drop(['Patient_ID'], axis=1, errors='ignore')\n",
    "\n",
    "    y_train_inter = y_train_inter.drop(['Patient_ID'], axis=1, errors='ignore')\n",
    "    y_test_inter = y_test_inter.drop(['Patient_ID'], axis=1, errors='ignore')\n",
    "    \n",
    "    simple_linear_regression(X_train_inter_feature_extracted, X_test_inter_feature_extracted, \\\n",
    "                         y_train_inter, y_test_inter, nb_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_slr_with_correlation(df_label_psd_cluster, df_label_spectro_cluster, df_label_microstate, \n",
    "                                 test_ratio, nb_features_extracted_psd, nb_features_extracted_spe, \n",
    "                                nb_features_extracted_mic, nb_cv):\n",
    "    \n",
    "    # Define Train and Test data \n",
    "    print()\n",
    "    print(\"---- Split into Train and Test data ----\")\n",
    "    print()\n",
    "    (X_train_psd, y_train_psd, X_test_psd, y_test_psd) = \\\n",
    "                                                        train_test_split(df_label_psd_cluster, test_ratio)\n",
    "    (X_train_spe, y_train_spe, X_test_spe, y_test_spe) = \\\n",
    "                                                        train_test_split(df_label_spectro_cluster, test_ratio)\n",
    "    (X_train_mic, y_train_mic, X_test_mic, y_test_mic) = \\\n",
    "                                                        train_test_split(df_label_microstate, test_ratio)\n",
    "\n",
    "    print(\"Test lengths: \" + str(len(y_test_psd)) + \"(psd), \" + \\\n",
    "         str(len(y_test_spe)) + \"(spectro), \" + str(len(y_test_mic)) + \"(micro)\")\n",
    "    \n",
    "    # Feature selection by correlation\n",
    "    print()\n",
    "    print(\"---- Feature selection by correlation ----\")\n",
    "    print()\n",
    "    X_train_psd_feature_extracted, X_test_psd_feature_extracted = \\\n",
    "            feature_selection_by_correlation(X_train_psd, y_train_psd, X_test_psd, nb_features_extracted_psd)\n",
    "    X_train_spe_feature_extracted, X_test_spe_feature_extracted = \\\n",
    "            feature_selection_by_correlation(X_train_spe, y_train_spe, X_test_spe, nb_features_extracted_spe)\n",
    "    X_train_mic_feature_extracted, X_test_mic_feature_extracted = \\\n",
    "            feature_selection_by_correlation(X_train_mic, y_train_mic, X_test_mic, nb_features_extracted_mic)\n",
    "    \n",
    "    # Simple Linear Regressions\n",
    "    print()\n",
    "    print(\"---- Simple Linear Regressions ----\")\n",
    "    print()\n",
    "\n",
    "    # Train Power Spectrum Cluster SLR\n",
    "    regr_psd, train_mse_psd = fit_simple_linear_regression(\n",
    "        X_train_psd_feature_extracted.drop(['Patient_ID'], axis=1, errors='ignore'),\n",
    "        y_train_psd.drop(['Patient_ID'], axis=1, errors='ignore'), \n",
    "        nb_cv)\n",
    "\n",
    "    # Train Spectro SLR\n",
    "    regr_spe, train_mse_spe = fit_simple_linear_regression(\n",
    "        X_train_spe_feature_extracted.drop(['Patient_ID'], axis=1, errors='ignore'),\n",
    "        y_train_spe.drop(['Patient_ID'], axis=1, errors='ignore'), \n",
    "        nb_cv)\n",
    "\n",
    "    # Train Microstate\n",
    "    regr_mic, train_mse_mic = fit_simple_linear_regression(\n",
    "        X_train_mic_feature_extracted.drop(['Patient_ID'], axis=1, errors='ignore'),\n",
    "        y_train_mic.drop(['Patient_ID'], axis=1, errors='ignore'),\n",
    "        nb_cv)\n",
    "    \n",
    "    # Make the union of the test data sets\n",
    "    union_test_patient_ids = pd.merge(X_test_psd['Patient_ID'], X_test_spe['Patient_ID'], \\\n",
    "                                      on='Patient_ID', how='outer')\n",
    "    union_test_patient_ids = pd.merge(union_test_patient_ids, X_test_mic['Patient_ID'], \\\n",
    "                                      on='Patient_ID', how='outer')\n",
    "\n",
    "    # Make an ensemble testing, weightened by train mse score\n",
    "\n",
    "    sse = 0\n",
    "    for test_patient_id in union_test_patient_ids[\"Patient_ID\"]:\n",
    "\n",
    "        y_pred = [0, 0, 0]\n",
    "        weights = [0, 0, 0]\n",
    "\n",
    "        if test_patient_id in X_test_psd['Patient_ID'].values:\n",
    "            test_sample = X_test_psd_feature_extracted[X_test_psd_feature_extracted['Patient_ID']==test_patient_id]\n",
    "            test_sample = test_sample.drop(['Patient_ID'], axis=1)\n",
    "\n",
    "            y_pred[0] = regr_psd.predict(test_sample)[0][0]\n",
    "            weights[0] = 1.0/train_mse_psd\n",
    "            y_test = y_test_psd[y_test_psd['Patient_ID']==test_patient_id]['Age'].values[0]\n",
    "\n",
    "        if test_patient_id in X_test_spe['Patient_ID'].values:\n",
    "            test_sample = X_test_spe_feature_extracted[X_test_spe_feature_extracted['Patient_ID']==test_patient_id]\n",
    "            test_sample = test_sample.drop(['Patient_ID'], axis=1)\n",
    "\n",
    "            y_pred[1] = regr_spe.predict(test_sample)[0][0]\n",
    "            weights[1] = 1.0/train_mse_spe\n",
    "            y_test = y_test_spe[y_test_spe['Patient_ID']==test_patient_id]['Age'].values[0]\n",
    "\n",
    "        if test_patient_id in X_test_mic['Patient_ID'].values:\n",
    "            test_sample = X_test_mic_feature_extracted[X_test_mic_feature_extracted['Patient_ID']==test_patient_id]\n",
    "            test_sample = test_sample.drop(['Patient_ID'], axis=1)\n",
    "\n",
    "            y_pred[2] = regr_mic.predict(test_sample)[0][0]\n",
    "            weights[2] = 1.0/train_mse_mic\n",
    "            y_test = y_test_mic[y_test_mic['Patient_ID']==test_patient_id]['Age'].values[0]\n",
    "\n",
    "        weights = weights/sum(weights)\n",
    "        y_pred = np.sum(np.multiply(y_pred, weights))\n",
    "\n",
    "        sse = sse + (y_pred - y_test)**2\n",
    "\n",
    "    test_mse = sse/len(union_test_patient_ids)\n",
    "    print(\"----- Test results --------\")\n",
    "    print('Mean squared error: %.2f'% test_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_median(dataframe_with_nan):\n",
    "    \n",
    "    for column in dataframe_with_nan:\n",
    "        if not isinstance(dataframe_with_nan[column].values[0], str): \n",
    "            median = dataframe_with_nan[column].median()\n",
    "            dataframe_with_nan[column].fillna(median, inplace=True)\n",
    "\n",
    "    return dataframe_with_nan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
